{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb65a01-435d-4225-ac37-8cdeff8ecf02",
   "metadata": {},
   "source": [
    "5. Implement the Continuous Bag of Words (CBOW) Model. Stages can be:\n",
    "<br>\n",
    "a. Data preparation\n",
    "<br>\n",
    "b. Generate training data\n",
    "<br>\n",
    "c. Train model\n",
    "<br>\n",
    "d. Output \n",
    "\n",
    "Video link - https://youtu.be/Q95SIG4g7SA?si=QOjS5tqjIzzk2bEl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cfa89a6-398f-49c0-82bf-f44aceb39f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Embedding, Lambda\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d66dfe7",
   "metadata": {},
   "source": [
    "This code imports necessary libraries and modules for implementing the Continuous Bag of Words (CBOW) model. Here's an explanation of each import statement:\n",
    "\n",
    "1. `import tensorflow as tf`: Imports the TensorFlow library, which is an open-source machine learning framework developed by Google for building and training machine learning models.\n",
    "\n",
    "2. `from tensorflow.keras.models import Sequential`: Imports the Sequential class from the `tensorflow.keras.models` module. `Sequential` is used to create linear stack of layers for building neural networks layer by layer.\n",
    "\n",
    "3. `from tensorflow.keras.layers import Dense, Embedding, Lambda`: Imports specific layer classes (`Dense`, `Embedding`, and `Lambda`) from the `tensorflow.keras.layers` module. \n",
    "    - `Dense`: A regular densely connected neural network layer.\n",
    "    - `Embedding`: Represents an embedding layer that maps integers (representing specific words) to dense vectors of fixed size.\n",
    "    - `Lambda`: Allows you to wrap arbitrary expressions as a Layer object.\n",
    "\n",
    "4. `from tensorflow.keras.preprocessing.text import Tokenizer`: Imports the `Tokenizer` class from the `tensorflow.keras.preprocessing.text` module. `Tokenizer` is used to convert text into tokens (words or subwords) for text processing tasks.\n",
    "\n",
    "5. `import numpy as np`: Imports the NumPy library, a powerful library for numerical computing in Python. NumPy provides support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays.\n",
    "\n",
    "6. `import matplotlib.pyplot as plt`: Imports the `pyplot` module from the Matplotlib library. Matplotlib is a popular data visualization library in Python, and `pyplot` provides a convenient interface for creating static, animated, and interactive plots and figures.\n",
    "\n",
    "7. `from sklearn.decomposition import PCA`: Imports the PCA (Principal Component Analysis) class from the scikit-learn library. PCA is a dimensionality reduction technique used for visualizing high-dimensional data in lower dimensions while preserving important features.\n",
    "\n",
    "8. `import re`: Imports the regular expression module in Python. Regular expressions (regex) are used for pattern matching and manipulation of strings in text processing tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c021937-7e54-4167-8efd-841824fbafcc",
   "metadata": {},
   "source": [
    "#### a. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73f3a2ac-5050-4889-b3d9-74400034ea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5b9feb2-baec-4b6f-b697-12ce66881706",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc8bf257-d6c8-4b73-9b23-73aedeeea4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are about to study the idea of a computational process',\n",
       " '\\nComputational processes are abstract beings that inhabit computers',\n",
       " '\\nAs they evolve, processes manipulate other abstract things called data',\n",
       " '\\nThe evolution of a process is directed by a pattern of rules\\ncalled a program',\n",
       " ' People create programs to direct processes',\n",
       " ' In effect,\\nwe conjure the spirits of the computer with our spells',\n",
       " '']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996a58d6-8e83-443f-9038-76afad3003de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean Data\n",
    "clean_sentences = []\n",
    "for sentence in sentences:\n",
    "    # skip empty string\n",
    "    if sentence == \"\":\n",
    "        continue;\n",
    "    # remove special characters\n",
    "    sentence = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n",
    "    # remove 1 letter words\n",
    "    sentence = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentence).strip()\n",
    "    # lower all characters\n",
    "    sentence = sentence.lower()\n",
    "    clean_sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473bf51",
   "metadata": {},
   "source": [
    "This code snippet performs the \"Data Preparation\" stage. It processes a list of sentences, cleaning and preprocessing the text data before using it to train the Continuous Bag of Words (CBOW) model. Here's what each step does:\n",
    "\n",
    "1. **Loop through Sentences:**\n",
    "   ```python\n",
    "   clean_sentences = []\n",
    "   for sentence in sentences:\n",
    "   ```\n",
    "   It initializes an empty list `clean_sentences` to store the cleaned versions of the input sentences. The loop iterates through each sentence in the `sentences` list.\n",
    "\n",
    "2. **Skip Empty Sentences:**\n",
    "   ```python\n",
    "   if sentence == \"\":\n",
    "       continue;\n",
    "   ```\n",
    "   This conditional statement checks if the current sentence is empty. If it is empty, the loop skips to the next iteration using the `continue` statement.\n",
    "\n",
    "3. **Remove Special Characters:**\n",
    "   ```python\n",
    "   sentence = re.sub('[^A-Za-z0-9]+', ' ', sentence)\n",
    "   ```\n",
    "   This line of code uses a regular expression (`re.sub()`) to remove all special characters from the `sentence`. It replaces any non-alphanumeric characters with a space (' ').\n",
    "\n",
    "4. **Remove Single Letter Words:**\n",
    "   ```python\n",
    "   sentence = re.sub(r'(?:^| )\\w(?:$| )', ' ', sentence).strip()\n",
    "   ```\n",
    "   This regular expression removes single-letter words from the `sentence`. It matches and removes any standalone single letter, surrounded by spaces. The `strip()` function removes any leading or trailing spaces after the removal of single-letter words.\n",
    "\n",
    "5. **Convert to Lowercase:**\n",
    "   ```python\n",
    "   sentence = sentence.lower()\n",
    "   ```\n",
    "   This line converts all characters in the `sentence` to lowercase. This ensures that the model treats uppercase and lowercase versions of the same word as identical, preventing the model from treating them as distinct tokens.\n",
    "\n",
    "6. **Append Cleaned Sentence:**\n",
    "   ```python\n",
    "   clean_sentences.append(sentence)\n",
    "   ```\n",
    "   Finally, the cleaned `sentence` is added to the `clean_sentences` list after all the preprocessing steps have been applied.\n",
    "\n",
    "After this loop completes for all sentences in the input `sentences` list, the `clean_sentences` list contains the preprocessed and cleaned version of the input data. These clean sentences can then be used for generating training data and training the CBOW model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9286c8b6-ae81-4c6c-926e-31fe6fc3ecc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we are about to study the idea of computational process',\n",
       " 'computational processes are abstract beings that inhabit computers',\n",
       " 'as they evolve processes manipulate other abstract things called data',\n",
       " 'the evolution of process is directed by pattern of rules called program',\n",
       " 'people create programs to direct processes',\n",
       " 'in effect we conjure the spirits of the computer with our spells']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9218e589-294c-4892-8e4c-6a0b46d63cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After converting our words in the corpus into vector of integers:\n",
      "[[4, 5, 11, 6, 12, 1, 13, 2, 7, 8], [7, 3, 5, 9, 14, 15, 16, 17], [18, 19, 20, 3, 21, 22, 9, 23, 10, 24], [1, 25, 2, 8, 26, 27, 28, 29, 2, 30, 10, 31], [32, 33, 34, 6, 35, 3], [36, 37, 4, 38, 1, 39, 2, 1, 40, 41, 42, 43]]\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = clean_sentences\n",
    "\n",
    "# Convert the corpus to a sequence of integers\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "sequences = tokenizer.texts_to_sequences(corpus)\n",
    "print(\"After converting our words in the corpus \\\n",
    "into vector of integers:\")\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535e900",
   "metadata": {},
   "source": [
    "This code block is responsible for converting the cleaned sentences (corpus) into sequences of integers. It also demonstrates the use of the `Tokenizer` class from TensorFlow's Keras API. Here's a step-by-step explanation:\n",
    "\n",
    "1. **Define the Corpus:**\n",
    "   ```python\n",
    "   corpus = clean_sentences\n",
    "   ```\n",
    "   The variable `corpus` is set to the list of previously cleaned and preprocessed sentences stored in `clean_sentences`.\n",
    "\n",
    "2. **Create a Tokenizer:**\n",
    "   ```python\n",
    "   tokenizer = Tokenizer()\n",
    "   ```\n",
    "   An instance of the `Tokenizer` class is created. The `Tokenizer` is used to convert text data into numerical sequences.\n",
    "\n",
    "3. **Fit the Tokenizer on the Corpus:**\n",
    "   ```python\n",
    "   tokenizer.fit_on_texts(corpus)\n",
    "   ```\n",
    "   The `fit_on_texts` method of the `Tokenizer` is called with the `corpus` as its argument. This step processes the text data and builds an internal vocabulary, mapping words to unique integer indices. It prepares the tokenizer to convert words to integers using this vocabulary.\n",
    "\n",
    "4. **Convert the Corpus to Sequences of Integers:**\n",
    "   ```python\n",
    "   sequences = tokenizer.texts_to_sequences(corpus)\n",
    "   ```\n",
    "   The `texts_to_sequences` method of the `tokenizer` is called with the `corpus` as input. This method replaces each word in the `corpus` with its corresponding integer index from the vocabulary created earlier. As a result, you get a list of sequences, where each sequence represents a sentence as a sequence of integer values.\n",
    "\n",
    "5. **Print the Sequences:**\n",
    "   ```python\n",
    "   print(\"After converting our words in the corpus into vector of integers:\")\n",
    "   print(sequences)\n",
    "   ```\n",
    "   This code block prints the resulting sequences of integers. These sequences are ready to be used as input data for training the Continuous Bag of Words (CBOW) model. Each integer in a sequence represents a word in the corpus, and the sequences can be used to predict the target word based on the context words in the CBOW model.\n",
    "\n",
    "After this code block, you have successfully converted your text data into sequences of integers, which can be used to generate training data for the CBOW model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be572280-b97d-4175-9da2-035b134b311e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 11, 6, 12, 1, 13, 2, 7, 8]\n",
      "['we', 'are', 'about', 'to', 'study', 'the', 'idea', 'of', 'computational', 'process']\n",
      "[7, 3, 5, 9, 14, 15, 16, 17]\n",
      "['computational', 'processes', 'are', 'abstract', 'beings', 'that', 'inhabit', 'computers']\n",
      "[18, 19, 20, 3, 21, 22, 9, 23, 10, 24]\n",
      "['as', 'they', 'evolve', 'processes', 'manipulate', 'other', 'abstract', 'things', 'called', 'data']\n",
      "[1, 25, 2, 8, 26, 27, 28, 29, 2, 30, 10, 31]\n",
      "['the', 'evolution', 'of', 'process', 'is', 'directed', 'by', 'pattern', 'of', 'rules', 'called', 'program']\n",
      "[32, 33, 34, 6, 35, 3]\n",
      "['people', 'create', 'programs', 'to', 'direct', 'processes']\n",
      "[36, 37, 4, 38, 1, 39, 2, 1, 40, 41, 42, 43]\n",
      "['in', 'effect', 'we', 'conjure', 'the', 'spirits', 'of', 'the', 'computer', 'with', 'our', 'spells']\n"
     ]
    }
   ],
   "source": [
    "# creating dictionary for word to index and index to word\n",
    "index_to_word_map = {}\n",
    "word_to_index_map = {}\n",
    "for index_1, sequence in enumerate(sequences):\n",
    "    print(sequence)\n",
    "    words_in_sentence = clean_sentences[index_1].split()\n",
    "    print(words_in_sentence)\n",
    "    for index_2, value in enumerate(sequence):\n",
    "        index_to_word_map[value] = words_in_sentence[index_2]\n",
    "        word_to_index_map[words_in_sentence[index_2]] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5a6de",
   "metadata": {},
   "source": [
    "In this code block, two dictionaries (`index_to_word_map` and `word_to_index_map`) are created to map words to their corresponding integer indices and vice versa. Here's what each step does:\n",
    "\n",
    "1. **Initialize Empty Dictionaries:**\n",
    "   ```python\n",
    "   index_to_word_map = {}\n",
    "   word_to_index_map = {}\n",
    "   ```\n",
    "   Two empty dictionaries, `index_to_word_map` and `word_to_index_map`, are initialized. These dictionaries will be used to store the mapping between words and their corresponding integer indices.\n",
    "\n",
    "2. **Loop through Sequences and Words:**\n",
    "   ```python\n",
    "   for index_1, sequence in enumerate(sequences):\n",
    "       words_in_sentence = clean_sentences[index_1].split()\n",
    "       for index_2, value in enumerate(sequence):\n",
    "   ```\n",
    "   The code uses nested loops to iterate over each sequence of integers (`sequence`) and the corresponding words in the original cleaned sentences (`words_in_sentence`).\n",
    "\n",
    "3. **Create Mapping:**\n",
    "   ```python\n",
    "   index_to_word_map[value] = words_in_sentence[index_2]\n",
    "   word_to_index_map[words_in_sentence[index_2]] = value\n",
    "   ```\n",
    "   For each word in the `words_in_sentence`, the code maps the integer index (`value`) to the word in `index_to_word_map` and maps the word to the integer index in `word_to_index_map`. This creates a bidirectional mapping between words and their corresponding indices.\n",
    "\n",
    "   - `index_to_word_map`: Maps integers to words. The keys are integer indices, and the values are the corresponding words from the sentences.\n",
    "   - `word_to_index_map`: Maps words to integers. The keys are words, and the values are the corresponding integer indices.\n",
    "\n",
    "After this code block, you have created two dictionaries that allow you to easily look up the index of a word (`word_to_index_map`) or retrieve the word given its index (`index_to_word_map`). These mappings are essential for converting words to integers when preparing the input data for the Continuous Bag of Words (CBOW) model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7cfbee67-7458-4486-b589-284c7d453538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 'we', 5: 'are', 11: 'about', 6: 'to', 12: 'study', 1: 'the', 13: 'idea', 2: 'of', 7: 'computational', 8: 'process', 3: 'processes', 9: 'abstract', 14: 'beings', 15: 'that', 16: 'inhabit', 17: 'computers', 18: 'as', 19: 'they', 20: 'evolve', 21: 'manipulate', 22: 'other', 23: 'things', 10: 'called', 24: 'data', 25: 'evolution', 26: 'is', 27: 'directed', 28: 'by', 29: 'pattern', 30: 'rules', 31: 'program', 32: 'people', 33: 'create', 34: 'programs', 35: 'direct', 36: 'in', 37: 'effect', 38: 'conjure', 39: 'spirits', 40: 'computer', 41: 'with', 42: 'our', 43: 'spells'}\n",
      "\n",
      "\n",
      "{'we': 4, 'are': 5, 'about': 11, 'to': 6, 'study': 12, 'the': 1, 'idea': 13, 'of': 2, 'computational': 7, 'process': 8, 'processes': 3, 'abstract': 9, 'beings': 14, 'that': 15, 'inhabit': 16, 'computers': 17, 'as': 18, 'they': 19, 'evolve': 20, 'manipulate': 21, 'other': 22, 'things': 23, 'called': 10, 'data': 24, 'evolution': 25, 'is': 26, 'directed': 27, 'by': 28, 'pattern': 29, 'rules': 30, 'program': 31, 'people': 32, 'create': 33, 'programs': 34, 'direct': 35, 'in': 36, 'effect': 37, 'conjure': 38, 'spirits': 39, 'computer': 40, 'with': 41, 'our': 42, 'spells': 43}\n"
     ]
    }
   ],
   "source": [
    "print(index_to_word_map)\n",
    "print(\"\\n\")\n",
    "print(word_to_index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a247e23-8497-43a9-b415-971bd592090a",
   "metadata": {},
   "source": [
    "#### b. Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c83dfb9-4a0d-4bdc-acec-4528ed388fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameters\n",
    "vocab_size = len(word_to_index_map) + 1\n",
    "embedding_size = 10\n",
    "window_size = 2\n",
    "\n",
    "# Generate the context-target pairs\n",
    "contexts = []\n",
    "targets = []\n",
    "for sequence in sequences:\n",
    "\tfor i in range(window_size, len(sequence) - window_size):\n",
    "\t\tcontext = sequence[i - window_size:i] + sequence[i + 1:i + window_size + 1]\n",
    "\t\ttarget = sequence[i]\n",
    "\t\tcontexts.append(context)\n",
    "\t\ttargets.append(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4390a51",
   "metadata": {},
   "source": [
    "In this code block, the parameters for the Continuous Bag of Words (CBOW) model are defined, and the context-target pairs are generated based on the specified window size. Here's what each part of the code does:\n",
    "\n",
    "1. **Define Parameters:**\n",
    "   ```python\n",
    "   vocab_size = len(tokenizer.word_index) + 1\n",
    "   embedding_size = 10\n",
    "   window_size = 2\n",
    "   ```\n",
    "   - `vocab_size`: Represents the size of the vocabulary. It is calculated as the total number of unique words in the corpus (as obtained from the tokenizer) plus 1. The additional 1 accounts for the out-of-vocabulary (OOV) token.\n",
    "   - `embedding_size`: Specifies the dimensionality of the word embeddings. Each word in the vocabulary will be represented as a dense vector of this size.\n",
    "   - `window_size`: Determines the number of words to consider to the left and right of the target word when generating context-target pairs. In this case, it is set to 2, meaning there will be 2 words to the left and 2 words to the right of the target word in the context window.\n",
    "\n",
    "2. **Generate Context-Target Pairs:**\n",
    "   ```python\n",
    "   contexts = []\n",
    "   targets = []\n",
    "   for sequence in sequences:\n",
    "       for i in range(window_size, len(sequence) - window_size):\n",
    "           context = sequence[i - window_size:i] + sequence[i + 1:i + window_size + 1]\n",
    "           target = sequence[i]\n",
    "           contexts.append(context)\n",
    "           targets.append(target)\n",
    "   ```\n",
    "   This nested loop iterates over each sequence of integers (`sequence`) in the `sequences` list. For each sequence, it considers a sliding window of size `window_size * 2 + 1` centered around the current word (indexed by `i`). It constructs the context by including words from `i - window_size` to `i - 1` and from `i + 1` to `i + window_size`. The target word is the word at index `i`.\n",
    "\n",
    "   - `contexts`: A list containing the context words (as sequences of integers) for each target word.\n",
    "   - `targets`: A list containing the target words (as integers) corresponding to the context words.\n",
    "\n",
    "These context-target pairs will be used as training data for the CBOW model. The model will learn to predict the target word based on its surrounding context words within the specified window size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12175cc9-f261-4867-be56-fb0f5e652c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'are', 'to', 'study'] => about\n",
      "['are', 'about', 'study', 'the'] => to\n",
      "['about', 'to', 'the', 'idea'] => study\n",
      "['to', 'study', 'idea', 'of'] => the\n",
      "['study', 'the', 'of', 'computational'] => idea\n"
     ]
    }
   ],
   "source": [
    "# sample of training data\n",
    "for i in range(5):\n",
    "    words = []\n",
    "    target = index_to_word_map.get(targets[i])\n",
    "    for j in contexts[i]:\n",
    "        words.append(index_to_word_map.get(j))\n",
    "    print(words, \"=>\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0ec03a5-0b78-4b6e-8472-d777e3c12cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the contexts and targets to numpy arrays\n",
    "X = np.array(contexts)\n",
    "Y = np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8590a96-3fd5-4460-b7bf-ead26c93f187",
   "metadata": {},
   "source": [
    "#### c. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "263e9e11-7802-43c3-93d0-c7d78a9e99d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 7ms/step - loss: 3.7842 - accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.7754 - accuracy: 0.2059\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.7684 - accuracy: 0.1765\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7610 - accuracy: 0.1471\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.7527 - accuracy: 0.2353\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7433 - accuracy: 0.2059\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.7327 - accuracy: 0.2353\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.7208 - accuracy: 0.2353\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.7069 - accuracy: 0.2059\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.6910 - accuracy: 0.2059\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.6731 - accuracy: 0.2059\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.6515 - accuracy: 0.2059\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 3.6267 - accuracy: 0.2059\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5957 - accuracy: 0.2059\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.5605 - accuracy: 0.2059\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.5214 - accuracy: 0.2059\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.4757 - accuracy: 0.2059\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 3.4270 - accuracy: 0.2059\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.3739 - accuracy: 0.2059\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.3183 - accuracy: 0.1765\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2658 - accuracy: 0.2059\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 3.2126 - accuracy: 0.2059\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.1688 - accuracy: 0.2059\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 16ms/step - loss: 3.1273 - accuracy: 0.2059\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 3.0945 - accuracy: 0.2059\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0665 - accuracy: 0.1765\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.0372 - accuracy: 0.1471\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.0125 - accuracy: 0.1471\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.9873 - accuracy: 0.1176\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.9615 - accuracy: 0.1176\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.9279 - accuracy: 0.1176\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8991 - accuracy: 0.1471\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.8645 - accuracy: 0.2059\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.8355 - accuracy: 0.2353\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.8012 - accuracy: 0.2353\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7644 - accuracy: 0.2353\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.7284 - accuracy: 0.2353\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6888 - accuracy: 0.2647\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.6450 - accuracy: 0.2941\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.6042 - accuracy: 0.2647\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5670 - accuracy: 0.2647\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.5266 - accuracy: 0.2647\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4854 - accuracy: 0.2647\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4460 - accuracy: 0.2647\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.4065 - accuracy: 0.2353\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.3706 - accuracy: 0.2353\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3363 - accuracy: 0.2353\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.3087 - accuracy: 0.2353\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.2796 - accuracy: 0.2353\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2366 - accuracy: 0.2353\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.1863 - accuracy: 0.2647\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 2.1364 - accuracy: 0.2647\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0898 - accuracy: 0.2941\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0492 - accuracy: 0.3529\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 2.0119 - accuracy: 0.3529\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.9812 - accuracy: 0.3529\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.9504 - accuracy: 0.3824\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.9182 - accuracy: 0.4118\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.8778 - accuracy: 0.4118\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.8400 - accuracy: 0.4706\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7980 - accuracy: 0.4706\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.7575 - accuracy: 0.4706\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.7198 - accuracy: 0.4412\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6865 - accuracy: 0.4706\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.6520 - accuracy: 0.4706\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.6169 - accuracy: 0.4706\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.5859 - accuracy: 0.4412\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5572 - accuracy: 0.4706\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.5299 - accuracy: 0.5588\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.4973 - accuracy: 0.5294\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4603 - accuracy: 0.5000\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.4258 - accuracy: 0.5588\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3933 - accuracy: 0.7059\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 1.3714 - accuracy: 0.6765\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.3525 - accuracy: 0.6765\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.3311 - accuracy: 0.6765\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2993 - accuracy: 0.6765\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.2712 - accuracy: 0.7059\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2394 - accuracy: 0.6471\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.2098 - accuracy: 0.6176\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1813 - accuracy: 0.6471\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1587 - accuracy: 0.6176\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.1412 - accuracy: 0.6471\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.1242 - accuracy: 0.5882\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.6471\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0980 - accuracy: 0.5882\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 1.0818 - accuracy: 0.6471\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.0604 - accuracy: 0.6471\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0344 - accuracy: 0.6765\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.0150 - accuracy: 0.7059\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0017 - accuracy: 0.7353\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9826 - accuracy: 0.7059\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9543 - accuracy: 0.6765\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9222 - accuracy: 0.7647\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.9066 - accuracy: 0.7353\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8973 - accuracy: 0.7647\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8934 - accuracy: 0.7941\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8795 - accuracy: 0.7941\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8689 - accuracy: 0.7647\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.8492 - accuracy: 0.7647\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.8338 - accuracy: 0.7941\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8217 - accuracy: 0.7059\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.8028 - accuracy: 0.7059\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7826 - accuracy: 0.7059\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7716 - accuracy: 0.7353\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7593 - accuracy: 0.7353\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7647\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7250 - accuracy: 0.7941\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.7128 - accuracy: 0.8235\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.7078 - accuracy: 0.8235\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6901 - accuracy: 0.8529\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6637 - accuracy: 0.8529\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6413 - accuracy: 0.8529\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.8529\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6173 - accuracy: 0.8235\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.7941\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6216 - accuracy: 0.7941\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6184 - accuracy: 0.7941\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6084 - accuracy: 0.7647\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5925 - accuracy: 0.8235\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5518 - accuracy: 0.8235\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5183 - accuracy: 0.8529\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5066 - accuracy: 0.8529\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.5180 - accuracy: 0.9118\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5216 - accuracy: 0.9118\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.5227 - accuracy: 0.9118\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.8824\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.5216 - accuracy: 0.8529\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.5109 - accuracy: 0.8529\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.8529\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8824\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4229 - accuracy: 0.9118\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4145 - accuracy: 0.9412\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4130 - accuracy: 0.9118\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.9118\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4169 - accuracy: 0.9118\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4178 - accuracy: 0.9118\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.4162 - accuracy: 0.8824\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.8824\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3794 - accuracy: 0.8824\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3589 - accuracy: 0.8824\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.9118\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3301 - accuracy: 0.9118\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3254 - accuracy: 0.9118\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3242 - accuracy: 0.9118\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3212 - accuracy: 0.8824\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.8824\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2973 - accuracy: 0.9412\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2749 - accuracy: 0.9706\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2626 - accuracy: 0.9706\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2633 - accuracy: 0.9706\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2693 - accuracy: 0.9706\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2751 - accuracy: 0.9706\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2789 - accuracy: 0.9412\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2801 - accuracy: 0.9412\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2658 - accuracy: 0.9706\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2485 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2388 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2253 - accuracy: 0.9706\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2223 - accuracy: 0.9412\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2226 - accuracy: 0.9412\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2220 - accuracy: 0.9412\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2237 - accuracy: 0.9412\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2255 - accuracy: 0.9412\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2244 - accuracy: 0.9412\n",
      "Epoch 167/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9412\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.2049 - accuracy: 0.9412\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1898 - accuracy: 0.9412\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1779 - accuracy: 0.9706\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1670 - accuracy: 0.9706\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9706\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1518 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1542 - accuracy: 0.9706\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1655 - accuracy: 0.9706\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1506 - accuracy: 0.9706\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1327 - accuracy: 0.9706\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1189 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1216 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1277 - accuracy: 0.9706\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1252 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1220 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1167 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1104 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1053 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0934 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0886 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0857 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0830 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.0806 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0787 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b4b2fe6730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the CBOW model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2 * window_size))\n",
    "model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, Y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026a3bf6",
   "metadata": {},
   "source": [
    "In this code block, the Continuous Bag of Words (CBOW) model is defined, compiled, and trained. Let me explain each part of the code:\n",
    "\n",
    "1. **Define the CBOW Model:**\n",
    "   ```python\n",
    "   model = Sequential()\n",
    "   model.add(Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2 * window_size))\n",
    "   model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))\n",
    "   model.add(Dense(256, activation='relu'))\n",
    "   model.add(Dense(512, activation='relu'))\n",
    "   model.add(Dense(units=vocab_size, activation='softmax'))\n",
    "   ```\n",
    "   - `Sequential()`: Initializes a sequential model, which is a linear stack of layers.\n",
    "   - `Embedding(input_dim=vocab_size, output_dim=embedding_size, input_length=2 * window_size)`: Adds an embedding layer to the model. The embedding layer converts integer indices (representing words) into dense vectors of fixed size (`embedding_size`).\n",
    "   - `Lambda(lambda x: tf.reduce_mean(x, axis=1))`: Adds a Lambda layer that calculates the mean of the embeddings along axis 1. This step averages the embeddings of the context words.\n",
    "   - `Dense(256, activation='relu')`: Adds a fully connected dense layer with 256 units and ReLU activation function.\n",
    "   - `Dense(512, activation='relu')`: Adds another fully connected dense layer with 512 units and ReLU activation function.\n",
    "   - `Dense(units=vocab_size, activation='softmax')`: Adds the output layer with `vocab_size` units (equal to the number of unique words in the vocabulary) and softmax activation function. This layer produces a probability distribution over the vocabulary, allowing the model to predict the next word.\n",
    "\n",
    "2. **Compile the Model:**\n",
    "   ```python\n",
    "   model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "   ```\n",
    "   The model is compiled with the specified loss function (`sparse_categorical_crossentropy`), optimizer (`adam`), and evaluation metric (`accuracy`). The model will optimize its weights to minimize the categorical crossentropy loss between the predicted and actual word indices.\n",
    "\n",
    "3. **Train the Model:**\n",
    "   ```python\n",
    "   model.fit(X, Y, epochs=200, verbose=1)\n",
    "   ```\n",
    "   This line trains the model using the input data `X` (context word sequences) and target data `Y` (target word indices) for 200 epochs. The `verbose=1` argument indicates that training progress will be displayed during the training process.\n",
    "\n",
    "After training, the model's weights will be optimized, allowing it to predict the target word based on the surrounding context words within the specified window size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc052344",
   "metadata": {},
   "source": [
    "**d.output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00f936dd-06f2-4aea-a5f0-327fa3a7dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the word embeddings\n",
    "embeddings = model.get_weights()[0]\n",
    "\n",
    "# Perform PCA to reduce the dimensionality of the embeddings\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a8f2f",
   "metadata": {},
   "source": [
    "In this code block, the word embeddings learned by the Continuous Bag of Words (CBOW) model are obtained and then reduced in dimensionality using Principal Component Analysis (PCA). Here's what each part of the code does:\n",
    "\n",
    "1. **Get Word Embeddings from the Model:**\n",
    "   ```python\n",
    "   embeddings = model.get_weights()[0]\n",
    "   ```\n",
    "   The `get_weights()` method of the trained CBOW model retrieves the weights of the first layer, which is the embedding layer. The `embeddings` variable now contains the dense vectors representing each word in the vocabulary learned during training.\n",
    "\n",
    "2. **Perform PCA to Reduce Dimensionality:**\n",
    "   ```python\n",
    "   pca = PCA(n_components=2)\n",
    "   reduced_embeddings = pca.fit_transform(embeddings)\n",
    "   ```\n",
    "   An instance of the PCA class is created with `n_components=2`, indicating that PCA should reduce the dimensionality of the embeddings to 2 dimensions. The `fit_transform()` method applies PCA to the original embeddings, reducing their dimensionality and storing the result in the `reduced_embeddings` variable.\n",
    "\n",
    "After these steps, `reduced_embeddings` contains the word embeddings in a lower-dimensional space (2D) obtained through PCA. These reduced embeddings can be used for visualization or further analysis to understand the relationships between words in the learned embedding space. Dimensionality reduction techniques like PCA are often used to visualize high-dimensional data in a more interpretable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7f908298-5229-4a70-8abe-895e27ae35ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAGbCAYAAACszmWlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAByoElEQVR4nO3deVxV1fr48c9icEQhhxKHK+p1BA4HEERRECcsNefUnMhrlqWZpqnXNLL6Zumv1NvgtVtiaWpqWqa3zClxTFDEIc1UnKBECRREZVi/P5BzBUFBDhw4PO/Xixfstdfe+9lb5Dlr77XXUlprhBBCiLLOxtIBCCGEEOYgCU0IIYRVkIQmhBDCKkhCE0IIYRUkoQkhhLAKdpYO4H5q1aqlXVxcLB2GEEKIUiIyMvKK1rp2XutKdUJzcXEhIiLC0mEIIYQoJZRS5/JbJ7cchRBCWAVJaEIIIayCJDQhhBBWQRKaEEIIqyAJTQgBQGJiIh9//DEAO3bsoGfPnhaOSIjCkYQmhAByJjQhyiJJaEIIAKZNm8bp06cxGo1MmTKF5ORkBgwYQIsWLRg6dCjZM3NERkYSGBiIt7c3wcHBxMXFcfr0aby8vEz7OnXqFN7e3pY6FVFOSUITQgAwZ84cmjRpQlRUFHPnzuXQoUPMnz+f48ePc+bMGXbv3k1aWhrjx49nzZo1REZGMmrUKGbMmEGTJk1wdHQkKioKgCVLlhASEmLR8xHlT6l+sVoIYTm+vr7Ur18fAKPRSExMDE5OThw9epSuXbsCkJGRgbOzMwCjR49myZIlvP/++6xatYpffvnFYrGL8kkSmhAiTxUrVjT9bGtrS3p6OlprXF1d2bt37z31+/fvzxtvvEGnTp3w9vamZs2aJRmuEHLLUQiRpVq1aly/fv2+dZo3b058fLwpoaWlpXHs2DEAKlWqRHBwMGPHjuWZZ54p9niFyE0SmhACgJo1a+Lv74+bmxtTpkzJs06FChVYs2YNU6dOxcPDA6PRyJ49e0zrhw4dilKKbt26lVTYQpio7J5LpVHr1q21DE4sRNkxb948kpKSePPNNy0dirBSSqlIrXXrvNZJC01YLQcHB0uHUG7E/fEtAQE1+fjjGfj5/UTcH99aOiRRDkmnECFEkcT98S0nTszg9VAnwAmI58SJGQA41+ltwchEeSMtNFEqLVu2DF9fX4xGI8899xwfffQRr776qml9WFgY48ePB+D999/Hzc0NNzc35s+ff8++Bg0axKZNm0zLISEhrF27loyMDKZMmYKPjw8Gg4F///vfxX5e1ujM6XlkZqbmKMvMTOXM6XkWikiUV5LQRKnz66+/smrVKnbv3k1UVBS2trY4ODjwzTffmOqsWrWKQYMGERkZyZIlS9i/fz/79u3j008/5dChQzn2N3jwYFatWgXA7du32bp1K0888QSfffYZjo6OHDhwgAMHDvDpp59y9uzZEj1Xa3DzVlyhyoUoLpLQRKmzdetWIiMj8fHxwWg0snXrVs6ePUvjxo3Zt28fV69e5eTJk/j7+7Nr1y769u1L1apVcXBwoF+/foSHh+fY3+OPP862bdu4desW//3vfwkICKBy5cps3ryZL774AqPRSJs2bbh69SqnTp2y0FmXXZUqOheqXIjiIs/QRKmjtWbkyJG88847Oco/++wzvv76a1q0aEHfvn1RSlGQXrqVKlWiY8eO/Pjjj6xatYohQ4aYjvOvf/2L4ODgYjmP8qJxk8mcODEjx21HG5vKNG4y2YJRifJIWmii1OncuTNr1qzh8uXLACQkJHDu3Dn69evH+vXrWbFiBYMGDQIgICCA9evXc+PGDVJSUli3bh0dOnS4Z5+DBw9myZIlhIeHmxJYcHAwn3zyCWlpaQD89ttvpKSklNBZWg/nOr1p0eJtKlWsCygqVaxLixZvS4cQUeKkhSZKnVatWvHWW2/RrVs3MjMzsbe356OPPqJhw4a0atWK48eP4+vrC4CXlxchISGm5dGjR+Pp6XnPPrt168aIESN48sknqVChgqluTEwMXl5eaK2pXbs269evL7HztCbOdXpLAhMWJy9Wi3Jp7R8JvHMmjku30qhX0Z7pjZ3pX6eGpcMSQjzA/V6slhaaKHfW/pHA5JMXSM3M+jB38VYak09eAJCkJkQZJs/QRLnzzpk4UzLLlpqpeeeMdDMXoiyThCbKnUu30gpVLoQoGyShiXKnXkX7QpULIcoGSWii3Jne2JnKNipHWWUbxfTG8iKwEGWZdAoR5U52xw/p5SiEdZGEJsql/nVqSAITwsrILUchhBBWQRKaEEIIqyAJTQghhFWQhCaEEMIqSEITQghhFSShCSGEsApmSWhKqe5KqZNKqd+VUtPuU89HKZWhlBpgjuMKIYQQ2Yqc0JRStsBHwONAK2CIUqpVPvXeBX4s6jGFEEKI3MzRQvMFftdan9Fa3wZWAnnN9DceWAtcNsMxhRBCiBzMkdDqARfuWr54p8xEKVUP6AssetDOlFJjlFIRSqmI+Ph4M4QnhBCiPDBHQlN5lOWeBns+MFVrnfGgnWmtF2utW2utW9euXdsM4QkhhCgPzDGW40WgwV3L9YHYXHVaAyuVUgC1gCeUUula6/VmOL4QQghhloR2AGiqlGoEXAIGA0/fXUFr3Sj7Z6VUGPC9JDMhhBDmVOSEprVOV0qNI6v3oi3wudb6mFLq+TvrH/jcTAghhCgqs0wfo7XeBGzKVZZnItNah5jjmEIIIcTdZKQQIYQQVkESmhBCCKsgCU0IIYRVkIQmhBDCKkhCE0IIYRUkoQkhhLAKktCEEEJYBUloQgghrIIkNCHKkZiYGNzc3CwdhhDFQhKaEEIIqyAJTYhyJj09nZEjR2IwGBgwYAAbN26kb9++pvU//fQT/fr1s2CEQjwcSWhClDMnT55kzJgxREdHU716dY4fP86vv/5K9oS6S5Ys4ZlnnrFwlEIUniQ0IcqZBg0a4O/vD8CwYcPYvXs3w4cPZ9myZSQmJrJ3714ef/xxC0cpROGZZbR9IUTZcWei3RzLzzzzDL169aJSpUoMHDgQOzv50yDKHmmhCVHOnD9/nr179wKwYsUK2rdvT926dalbty5vvfUWISEhlg1QiIckCU2IcqZly5YsXboUg8FAQkICY8eOBWDo0KE0aNCAVq1aWThCIR6O3FcQohxxcXHh+PHjpuXo6Gj+/e9/k5SUxJYtW+jevbsFoxOiaKSFJkQ5FR0dzYYNG0hKSmLx4sVcuHABpRTR0dGWDk2IhyItNCHKqa1bt5KWlgbAmDFjANBas3XrVgwGgyVDE+KhSAtNiHIqKSmpUOVClHaS0IQopxwdHQtVLkRpJwlNiHKqc+fO2Nvb5yizt7enc+fOFopIiKKRZ2hClFPZz8m2bt1KUlISjo6OdO7cWZ6fiTJLEpoQ5ZjBYJAEJqyG3HIUQghhFSShCSGEsAqS0IQQQlgFSWhCCCGsgiQ0IYQQVkESmhBCCKsgCU0IIYRVkIRWjmVkZFg6BCGEMBtJaFYqJiaGFi1aMHLkSAwGAwMGDODGjRu4uLgwe/Zs2rdvz+rVq1mxYgXu7u64ubkxdepU0/Y//PADXl5eeHh4mIZCSklJYdSoUfj4+ODp6cm3334LwLFjx/D19cVoNGIwGDh16hQpKSn06NEDDw8P3NzcWLVqFQCRkZEEBgbi7e1NcHAwcXFxACxcuJBWrVphMBgYPHhwCV8tIYRV0FqX2i9vb28tHs7Zs2c1oHft2qW11vqZZ57Rc+fO1Q0bNtTvvvuu1lrrS5cu6QYNGujLly/rtLQ0HRQUpNetW6cvX76s69evr8+cOaO11vrq1ataa62nT5+uv/zyS6211n/99Zdu2rSpTk5O1uPGjdPLli3TWmt969YtfePGDb1mzRo9evRoUzyJiYn69u3bum3btvry5ctaa61Xrlypn3nmGa211s7OzvrmzZumfQshRF6ACJ1PzjBLC00p1V0pdVIp9btSaloe63srpaKVUlFKqQilVHtzHFfcX4MGDfD39wdg2LBh7Nq1C4BBgwYBcODAATp27Ejt2rWxs7Nj6NCh7Ny5k3379hEQEECjRo0AqFGjBgCbN29mzpw5GI1GOnbsyM2bNzl//jxt27bl//7v/3j33Xc5d+4clStXxt3dnS1btjB16lTCw8NxdHTk5MmTHD16lK5du2I0Gnnrrbe4ePEikDUE09ChQ1m2bBl2djIimxCi8Iqc0JRStsBHwONAK2CIUqpVrmpbAQ+ttREYBfynqMcVD6aUynO5atWqQFbrPC9a63u2zS5fu3YtUVFRREVFcf78eVq2bMnTTz/Nd999R+XKlQkODmbbtm00a9aMyMhI3N3dmT59OrNnz0Zrjaurq2n7I0eOsHnzZgA2btzIiy++SGRkJN7e3qSnp5vzUohSKDExkY8//ti0vGPHDnr27GnBiERZZ44Wmi/wu9b6jNb6NrAS6H13Ba11sv7fX8+qQN5/SYVZnT9/nr179wKwYsUK2rfP2TBu06YNP//8M1euXCEjI4MVK1YQGBhI27Zt+fnnnzl79iwACQkJAAQHB/Ovf/3LlAgPHToEwJkzZ2jcuDEvvfQSTz75JNHR0cTGxlKlShWGDRvG5MmTOXjwIM2bNyc+Pt4UU1paGseOHSMzM5MLFy4QFBTEe++9R2JiIsnJySVyjYTl5E5oRSUfgoQ5Elo94MJdyxfvlOWglOqrlDoBbCSrlZYnpdSYO7clI+Lj480QXvnVsmVLli5disFgICEhgbFjx+ZY7+zszDvvvENQUBAeHh54eXnRu3dvateuzeLFi+nXrx8eHh6mW5QzZ84kLS0Ng8GAm5sbM2fOBGDVqlW4ublhNBo5ceIEI0aM4MiRI6aOIm+//TavvfYaFSpUYM2aNUydOhUPDw+MRiN79uwhIyODYcOG4e7ujqenJxMnTsTJyamkL5coZu+//z5ubm64ubkxf/58pk2bxunTpzEajUyZMgWA5ORkBgwYQIsWLRg6dKjpw1N+nYk6duzIP//5TwIDA1mwYIHFzk2UEvk9XCvoFzAQ+M9dy8OBf92nfgCwpSD7lk4hD+/s2bPa1dXV0mE80Penv9ddV3fV7mHuuuvqrvr7099bOiRRDCIiIrSbm5tOTk7W169f161atdIHDx7M8Tu6fft2Xb16dX3hwgWdkZGh/fz8dHh4+H07EwUGBuqxY8da5JyEZXCfTiHmePp+EWhw13J9IPY+CXSnUqqJUqqW1vqKGY4vyqiNZzYSuieUmxk3AYhLiSN0TygAPRr3sGBkwtx27dpF3759Tc9v+/XrR3h4+D31fH19qV+/PgBGo5GYmBicnJxMnYkg6/1JZ2dn0zbZdxCEMEdCOwA0VUo1Ai4Bg4Gn766glPo7cFprrZVSXkAF4KoZji3y4eLiwtGjRy0dxn0tOLjAlMyy3cy4yYKDCyShWRmdTwek3CpWrGj62dbWlvT0dFNnouxnr7llJ0khivwMTWudDowDfgR+Bb7WWh9TSj2vlHr+TrX+wFGlVBRZPSIH6YL+hgur9UfKH4UqF2VXQEAA69ev58aNG6SkpLBu3Tr8/f25fv36A7fNrzORELmZ5YUfrfUmYFOuskV3/fwu8K45jiWsR52qdYhLicuzXFgXLy8vQkJC8PX1BWD06NF4e3vj7++Pm5sbjz/+OD165N0qz+5M9NJLL5GUlER6ejovv/wyrq6uJXkKogxQpbmh1Lp1ax0REWHpMEQxyf0MDaCSbSVC24XKLUeRv+ivYetsSLoIjvWh8ywwPGXpqEQJUUpFaq1b57VOhmQQFpOdtBYcXMAfKX9Qp2odJnhNkGQm8hf9NWx4CdJSs5aTLmQtgyQ1IS00IUQZ8oFbVhLLzbEBTCzdnaCEedyvhSaj7Qshyo6ki4UrF+WKJDQhRNnhWL9w5aJckYQmhCg7Os8C+8o5y+wrZ5WLck8SmhCi7DA8Bb0WZj0zQ2V977VQOoQIQHo5Wo3Q0FAcHByYPHmypUMRongZnpIEJvIkLbQyRGtNZmampcMQQohSSRJaKRcTE0PLli154YUX8PLywtbW1rRuzZo1hISE3LPN6dOn6d69O97e3nTo0IETJ04AsHr1atzc3PDw8CAgIKCkTkEIIUqE3HIsA06ePMmSJUv4+OOPcXBweGD9MWPGsGjRIpo2bcr+/ft54YUX2LZtG7Nnz+bHH3+kXr16JCYmFn/gQghRgiShlQENGzbEz8+vQHWTk5PZs2cPAwcONJXdunULAH9/f0JCQnjqqafo169fscQqhBCWIgmtDLh7egyllOnnmzdv3lM3MzMTJycnoqKi7lm3aNEi9u/fz8aNGzEajURFRVGzZs1iiVkIIUqaPEMrYx577DF+/fVXMjMzWbdu3T3rq1evTqNGjVi9ejWQ1ZHk8OHDQNaztTZt2jB79mxq1arFhQt5DCEkhBBllCS0MmbOnDn07NmTTp065Zi1927Lly/ns88+w8PDA1dXV7799lsApkyZgru7O25ubgQEBODh4VGSoQshRLGSwYnLgbV/JPDOmTgu3UqjXkV7pjd2pn+dGpYOCwAHBweSk5MLVHfHjh1UqFCBdu3ameXY8+fPZ8yYMVSpUsUs+xNCFD8ZnLgcW/tHApNPXuDirTQ0cPFWGpNPXmDtHwmWDq3QduzYwZ49e/Jcl56eXuj9zZ8/nxs3bhQ1LCFEKSGdQqzcO2fiSM3M2QpPzdS8cyauxFtpffr04cKFC9y8eZMJEyYwZswYAF555RW2b9/OI488wsqVK6lduzYLFy5k0aJF2NnZ0apVK+bMmcOiRYuwtbVl2bJl/Otf/+Kzzz6jRo0aHDp0CC8vLwYNGsTLL79MamoqlStXZsmSJTRv3pyMjAymTp3Kjz/+iFKKZ599Fq01sbGxBAUFUatWLbZv316i10IIYX5yy9HKOW+PIq9/YQXEBRlLNJaEhARq1KhBamoqPj4+/Pzzz9SqVYtly5YxdOhQZs+ezeXLl/nwww+pW7cuZ8+epWLFiiQmJuLk5HTP8F4hISFcuXKFb7/9FltbW65du0aVKlWws7Njy5YtfPLJJ6xdu5ZPPvmELVu2sGrVKuzs7ExxuLi4EBERQa1atUr0OgghHp7MWF2O1atoz8VbaXmWl7SFCxeaemZeuHCBU6dOYWNjw6BBgwAYNmyY6f04g8HA0KFD6dOnD3369Ml3nwMHDjSNnpKUlMTIkSM5deoUSinS0rLOe8uWLTz//PPY2WX9uteoUTqeHwohzEsSmpVr/M0XnElJ43ZKMvYGLyp6+1HZRjG9cd49JB8kKiqK2NhYnnjiiUJtZzQa0Vqzd+9eqlSpQseOHfN8jy77PbuNGzeyc+dOvvvuO958802OHTuW537vfkdv5syZBAUFsW7dOmJiYujYsSOQ9erC3e/vCSGsk3QKsXKtHCrT81EnWjw/gUreftSvaM+85g1Mz88yMjIKtb+oqCg2bdpU6DjS09OpXr06VapU4cSJE+zbtw/IehF8zZo1AHz11Ve0b9+ezMxMLly4QFBQEO+99x6JiYkkJydTrVo1rl+/nu8xkpKSqFevHgBhYWGm8m7durFo0SJTx5GEhKwOMQ/anxCibJGEZoXefvttmjdvTpcuXTh58iSGalVwWzyXf139nYh2rrzi58Xs2bNp3749q1evZvPmzbRt2xYvLy8GDhxo6kZ/4MAB2rVrh4eHB76+viQlJTFr1ixWrVqF0Whk1apVpKSkMGrUKHx8fPD09DS985aamsrgwYMxGAwMGjSIKlWqkJGRgcFgYObMmaahvKpWrcqxY8fw9vZm27ZtzJo1i4yMDIYNG4a7uzuenp5MnDgRJycnevXqxbp16zAajYSHh99z3q+++irTp0/H398/R6IePXo0f/vb3zAYDHh4ePDVV18BWWNePv744wQFBRX3P4kQoiRorUvtl7e3txaFExERod3c3HRKSopOSkrSTZo00XPnztUjR47Uq1ev1lpr3bBhQ/3uu+9qrbWOj4/XHTp00MnJyVprrefMmaPfeOMNfevWLd2oUSP9yy+/aK21TkpK0mlpaXrJkiX6xRdfNB1v+vTp+ssvv9Raa/3XX3/ppk2b6uTkZP3//t//088884zWWuvDhw9rW1tbfeDAgRK7DkII6wRE6HxyhjxDszLh4eH07dvX9LLwk08+mWe97I4Y+/bt4/jx4/j7+wNw+/Zt2rZty8mTJ3F2dsbHxwfIGlIrL5s3b+a7775j3rx5QNb4kufPn2fnzp289NJLQFYHD4PBYL6TfEhxf3zLmdPzuHkrjkoVnWncZDLOdXpbOiwhhJlIQrNCBekAkd2ZQmtN165dWbFiRY710dHRBdqP1pq1a9fSvHnzh4qjpMT98S0nTswgMzMVgJu3YjlxYgaAJDUhrIQ8Q7MyAQEBrFu3jtTUVK5fv86GDRvuW9/Pz4/du3fz+++/A3Djxg1+++03WrRoQWxsLAcOHADg+vXrpKen39ORIjg4mH/961/oO+8zHjp0yBTH8uXLATh69CjR0dFmP9fCOHN6nimZZcvMTOXM6XkWikgIYW6S0KxM9ogZRqOR/v3706FDh/vWr127NmFhYQwZMgSDwYCfnx8nTpygQoUKrFq1ivHjx+Ph4UHXrl25efMmQUFBHD9+3NQpZObMmaSlpWEwGHBzc2PmzJkAjB07luTkZAwGA++99x6+vr4lcfr5unkrrlDlQoiyR0YKEcUi5dBlrv0YQ0biLWydKlI92IWqno9aLJ7duztw81bsPeWVKtbF3//eHpNCiNJJBicWJSrl0GUSvzlFRmLWTNkZibdI/OYUKYcuWyymxk0mY2NTOUeZjU1lGjeZbKGIhBDmJglNmN21H2PQaZk5ynRaJtd+jLFMQGR1/GjR4m0qVawLKCpVrEuLFm9LhxAhrIj0chRml90yK2h5SXGu01sSmBBWTFpowuxsnSoWqlwIIcxBEpowu+rBLij7nL9ayt6G6sEulglICFEumCWhKaW6K6VOKqV+V0pNy2P9UKVU9J2vPUopD3McV5ROVT0fxalfU1OLzNapIk79mlq0l6MQwvoV+RmaUsoW+AjoClwEDiilvtNaH7+r2lkgUGv9l1LqcWAx0KaoxxalV1XPRyWBCSFKlDlaaL7A71rrM1rr28BKIMeTd631Hq31X3cW9wH1zXBcIYQQwsQcCa0ecOGu5Yt3yvLzD+C/+a1USo1RSkUopSLi4+PNEJ4QQojywBwJLa8RaPMcfkQpFURWQpua38601ou11q211q1r165thvCEEEKUB+Z4D+0i0OCu5frAPWMMKaUMwH+Ax7XWV81wXCGEEMLEHC20A0BTpVQjpVQFYDDw3d0VlFJ/A74BhmutfzPDMYUQQogcitxC01qnK6XGAT8CtsDnWutjSqnn76xfBMwCagIf35kjKz2/wSWFEEKIhyGj7QshhCgzZLR9IYQQVk8SmhBCCKsgCU0IIYRVkIQmhBDCKkhCE0IIYRUkoQkhhLAKktCEEEJYBUloQgghrIIkNCGEEFZBEpoQQgirIAlNCCGEVZCEJoQQwipIQhNCCGEVJKEJIYSwCpLQRLnyxBNPkJiYSGJiIh9//LGpfMeOHfTs2dOCkQkhikoSmihXNm3ahJOT0z0JTQhR9klCE1blvffeY+HChQBMnDiRTp06AbB161aGDRuGi4sLV65cYdq0aZw+fRqj0ciUKVMASE5OZsCAAbRo0YKhQ4dSmie/FULcSxKasCoBAQGEh4cDEBERQXJyMmlpaezatYsOHTqY6s2ZM4cmTZoQFRXF3LlzATh06BDz58/n+PHjnDlzht27d1vkHIQQD0cSmrAq3t7eREZGcv36dSpWrEjbtm2JiIggPDw8R0LLi6+vL/Xr18fGxgaj0UhMTEzJBC2EMAs7SwcghDnZ29vj4uLCkiVLaNeuHQaDge3bt3P69Glatmx5320rVqxo+tnW1pb09PTiDlcIYUbSQhNWJyAggHnz5hEQEECHDh1YtGgRRqMRpZSpTrVq1bh+/boFoxRCmJskNGF1OnToQFxcHG3btuWxxx6jUqVK99xurFmzJv7+/ri5uZk6hQghyjZVmntytW7dWkdERFg6DFEOrD90ibk/niQ2MZW6TpWZEtycPp71LB2WECIXpVSk1rp1XuvkGZoo99YfusT0b46QmpYBwKXEVKZ/cwRAkpoQZYjcchTl3twfT5qSWbbUtAzm/njSQhEJIR6GJDRR7sUmphaqXAhROklCK4fCwsIYN26cpcMoNeo6VS5UeUmR1waEKBxJaKLcmxLcnMr2tjnKKtvbMiW4uVn2//777+Pm5oabmxvz588nJiYGNzc30/p58+YRGhoKQMeOHfnnP/9JYGAgCxYsMMvxhSgvJKGVQjExMbRo0YKRI0diMBgYMGAAN27cIDIyksDAQLy9vQkODiYuLg6AqKgo/Pz8MBgM9O3bl7/++gvI+uP48ssv065dO9zc3Pjll1/uOVZ8fDz9+/fHx8cHHx+fcjncUx/PerzTz516TpVRQD2nyrzTz90sHUIiIyNZsmQJ+/fvZ9++fXz66aemf5/8JCYm8vPPP/PKK68U+fhClCeS0EqpkydPMmbMGKKjo6levTofffQR48ePZ82aNURGRjJq1ChmzJgBwIgRI3j33XeJjo7G3d2dN954w7SflJQU9uzZw8cff8yoUaPuOc6ECROYOHEiBw4cYO3atYwePbrEzrE06eNZj93TOnF2Tg92T+tktt6Nu3btom/fvlStWhUHBwf69etnGmsyP4MGDTLLsYtLWFgYsbGxpuX58+dz48YNC0YkRBbptl9KNWjQAH9/fwCGDRvG//3f/3H06FG6du0KQEZGBs7OziQlJZGYmEhgYCAAI0eOZODAgab9DBkyBMgaPePatWskJibmOM6WLVs4fvy4afnatWtcv36datWqFefplRt5veeZmJhIZmamafnmzZs51letWrXY4yqKsLAw3NzcqFu3LpCV0IYNG0aVKlUKvI+MjAxsbW0fXFGIQpAWWil19zBNkDVUk6urK1FRUURFRXHkyBE2b95c6P3kXs7MzGTv3r2m/V66dEmSmRkFBASwfv16bty4QUpKCuvWrePxxx/n8uXLXL16lVu3bvH9999bNMb8bnHPnj0bHx8f3NzcGDNmDFpr1qxZQ0REBEOHDsVoNLJgwQJiY2MJCgoiKCgIgM2bN9O2bVu8vLwYOHAgycnJALi4uDB79mzat2/P6tWrcXFx4fXXX8fLywt3d3dOnDhhycsgrIAktFLq/Pnz7N27F4AVK1bg5+dHfHy8qSwtLY1jx47h6OjII488YrqN9eWXX5paawCrVq0Csm59OTo64ujomOM43bp148MPPzQtR0VFFedplTteXl6EhITg6+tLmzZtGD16ND4+PsyaNYs2bdrQs2dPWrRoYekw77nF/fHHHzNu3DgOHDjA0aNHSU1N5fvvv2fAgAG0bt2a5cuXExUVxYQJE6hbty7bt29n+/btXLlyhbfeeostW7Zw8OBBWrduzfvvv286TqVKldi1axeDBw8GoFatWhw8eJCxY8cyb948S52+sBJyy7GUatmyJUuXLuW5556jadOmjB8/nuDgYF566SWSkpJIT0/n5ZdfxtXVlaVLl/L8889z48YNGjduzJIlS0z7eeSRR2jXrh3Xrl3j888/v+c4Cxcu5MUXX8RgMJCenk5AQACLFi0qyVO1epMmTWLSpEk5yl566SVeeumlrIXor2HrbAidz47e9aHCGSDPkX2KTe5b3AsXLqRRo0a899573Lhxg4SEBFxdXenVq9d997Nv3z6OHz9u2tft27dp27ataX3u54P9+vUDsqb9+eabb8x5SqIcMktCU0p1BxYAtsB/tNZzcq1vASwBvIAZWmv5KPYANjY29yQWo9HIzp0776lrNBrZt29fnvvp378/77zzTo6ykJAQQkJCIPpram2dzaqWF8GvPnQOBcNT5joFURDRX8OGlyDtzkvcSReylqFE/y3yujX9wgsvEBERQYMGDQgNDb3nWV9etNZ07dqVFStW5Lk+9/PB7Cl7ZLoeYQ5FvuWolLIFPgIeB1oBQ5RSrXJVSwBeAiSRlRbZf0iTLgD6f39Io7+2dGTly9bZ/0tm2dJSs8pLUO5b3O3btweybgkmJyezZs0aU93cU+/cvezn58fu3bv5/fffAbhx4wa//fZbSZ2GKOfM8QzNF/hda31Ga30bWAn0vruC1vqy1voAkGaG41k9FxcXjh49WuT97Nixg9at87l1VUr+kJZ7SRcLV15Msm9xGwwGEhISGDt2LM8++yzu7u706dMHHx8fU92QkBCef/55jEYjqampjBkzhscff5ygoCBq165NWFgYQ4YMwWAw4OfnZ9HOHn369MHb2xtXV1cWL15MRkYGISEhuLm54e7uzgcffGCx2IT5FXn6GKXUAKC71nr0neXhQBut9T1jKymlQoHk+91yVEqNAcYA/O1vf/M+d+5ckeIT+Qh1AvL6t1cQmliysZRnH7jdaSXn4tgAJhb9Q01BxMTE0LNnT7N8iCptEhISqFGjBqmpqfj4+LB06VKmTZvGTz/9BGS9QuHk5GTZIEWh3G/6GHO00FQeZQ+dJbXWi7XWrbXWrWvXrl2EsMR9OdYvXLkoHp1ngX2uMSPtK2eVW7G4P75l9+4ObN32d3bv7kDcH98Wy3EWLlyIh4cHfn5+XLhwgdu3b3PmzBnGjx/PDz/8QPXq1YvluMIyzJHQLgIN7lquD8TmU1eUFuX0D2mpY3gKei3MapGhsr73WliiHULMdYu7oOL++JYTJ2Zw81YsoLl5K5YTJ2aYPant2LGDLVu2sHfvXg4fPoynpye3bt3i8OHDdOzYkY8++qjcjoxjrczRy/EA0FQp1Qi4BAwGnjbDfkVxyv6DuXV21vMax/pZyUx6OZY8w1Pl6rqfOT2PzMycz28zM1M5c3oeznV657NV4SUlJfHII49QpUoVTpw4wb59+7hy5QqZmZn079+fJk2aZPX2FVajyAlNa52ulBoH/EhWt/3PtdbHlFLP31m/SClVB4gAqgOZSqmXgVZa62tFPb4ognL2h1SUDjdvxRWq/GF1796dRYsWYTAYaN68OX5+fly6dImOHTuahh7L/UqLKNvM8h6a1noTsClX2aK7fv6DrFuRQohyrlJF5zu3G+8tN6eKFSvy3//+17QcHR3N1q1befLJJ3F0dKRz584YDAazHlNYlgx9JYQoUY2bTMbGJufzWxubyjRuMrnYjhkdHc2GDRtISkoCsm5Hbtiwgejo6GI7pih5ktCEECXKuU5vWrR4m0oV6wKKShXr0qLF22Z9fpbb1q1bSUvL+RpsWloaW7duLbZjFreoqCg2bdr04IrliIzlKIQocc51ehdrAsstu2VW0PKyICoqioiICJ544okCb5Oeno6dnfX+2ZcWmhDC4sLCwhg3LmsshtDQ0EKPvO/g4HDf9blnmXhQeUF88cUXGAwGPDw8GD58OOfOnTM9l+vcuTPnz58HskZWGTt2LEFBQTRu3Jiff/6ZUaNG0bJlyxy9LB0cHHjllVfw8vKic+fOxMfHA1kzz0dERABw5coVXFxcuH37NrNmzWLVqlUYjUZWrVpFSkoKo0aNwsfHB09PT779Nus1iLCwMAYOHEivXr3o1q0bcXFxBAQEYDQacXNze+CEs2WJJLQSkpGRYekQhCi3OnfujL29fY4ye3t7Onfu/FD7O3bsGG+//Tbbtm3j8OHDLFiwgHHjxjFixAiio6MZOnTo/2ZTAP766y+2bdvGBx98QK9evZg4cSLHjh3jyJEjpimbUlJS8PLy4uDBgwQGBuaYeT63ChUqMHv2bAYNGkRUVBSDBg3i7bffplOnThw4cIDt27czZcoUUlJSANi7dy9Lly5l27ZtfPXVVwQHBxMVFcXhw4cxGo0PdQ1KI0loZpDfBIm5JzRcsWIF7u7uuLm5MXXqVNP2P/zwA15eXnh4eJj+g+X3aevYsWP4+vpiNBoxGAycOnWKlJQUevTogYeHB25ubqY50ISwtNytmA0bNtCmTRs8PT3p0qULf/755323P336NN27d8fb25sOHTqYxoU8e/Ysbdu2xcfHh5kzZz4wDoPBQK9evUwtMkdHR3r16vXQvRy3bdvGgAEDqFWrFgA1atRg7969PP101iu4w4cPZ9euXab6vXr1QimFu7s7jz32GO7u7tjY2ODq6kpMTAyQNcNG9vQ6w4YNy7F9QWzevJk5c+ZgNBrp2LEjN2/eNLUSu3btSo0aNQDw8fFhyZIlhIaGcuTIEaua0Nd6b6aWsJMnT/LZZ5/h7+/PqFGj+Pjjj4H/TWgYGxuLn58fkZGRPPLII3Tr1o3169fj7+/Ps88+y86dO2nUqBEJCQkApk9bn3/+OYmJifj6+tKlSxcWLVrEhAkTGDp0KLdv3yYjI4NNmzZRt25dNm7cCJTt5wLCemS3Ynbv3k2tWrVISEhAKcW+fftQSvGf//yH9957j//3//5fvvsYM2YMixYtomnTpuzfv58XXniBbdu2MWHCBMaOHcuIESP46KOPChSPwWAwWzd9rfU9U+7kdvf67GlybGxsTD9nL+c3bU729nZ2dqb35u43hY/WmrVr19K8efMc5fv3788xbU9AQAA7d+5k48aNDB8+nClTpjBixIj7nktZIS00M8k9QWL2p6vsT1wHDhygY8eO1K5dGzs7O4YOHcrOnTvZt28fAQEBNGrUCMD0KSq/T1tt27bl//7v/3j33Xc5d+4clStXxt3dnS1btjB16lTCw8OL9FxACHPZtm0b9erV46uvvgLgzTffJDg4mODgYBo1asSkSZP4+eefadu2La+//jo//PADycnJpu2Tk5PZs2cPAwcOxGg08txzzxEXl/Xy9e7duxkyZAiQ1RoqaZ07d+brr7/m6tWrQNYgyO3atWPlypUALF++3DQFT0FlZmaapun56quvTNu7uLgQGRkJcN9pfIKDg/nXv/5F9oDzhw4dyvM4586d49FHH+XZZ5/lH//4BwcPHixUnKWZtNDMJK8JEuF/ExrmN6tBfp/08vu01bJlS9q0acPGjRsJDg7mP//5D506dSIyMpJNmzYxffp0unXrxqxZMiajsCytNQ0bNiQ8PJyXXnqJiIgITpw4QVhYGEeOHOHSpUt8/fXXXLp0idWrV7N48WLef/990/aZmZk4OTmZnjHl9qAWUnFydXVlxowZBAYGYmtri6enJwsXLmTUqFHMnTuX2rVr55g5viCqVq3KsWPH8Pb2xtHR0fToYPLkyTz11FN8+eWXdOrUyVQ/KCjI9KF3+vTpzJw5k5dffhmDwYDWGhcXF77//vt7jrNjxw7mzp2Lvb09Dg4OfPHFF0W7GKWJ1rrUfnl7e+uy4OzZsxrQe/bs0VprPXr0aD1v3jzdsGFDHR8fr7XWOjY2Vv/tb3/T8fHxOj09XXfu3FmvX79eX758WdevX1+fOXNGa6311atXtdZaT58+Xb/44os6MzNTa631wYMHtdZanz592lQ2YcIE/cEHH+hLly7p1NRUrbXW69at07179y6xcxciP0ePHtV///vf9d/+9jd97do1HRAQoGvVqqU///xz3blzZ+3r66vt7Oy0h4eHbtCggX7kkUf0qFGj9Ouvv67nzp2rtda6bdu2+uuvv9Zaa52ZmamjoqK01lr36tVLf/nll1prrT/++GNdtWpVy5ykGVnDOZQEIELnkzPklqOZ5DVB4t2cnZ155513CAoKwsPDAy8vL3r37k3t2rVZvHgx/fr1w8PDw3SLcubMmaSlpWEwGHBzczM9+F61ahVubm4YjUZOnDjBiBEjOHLkiKmjyNtvv81rr71W4ucvRG6urq689tprXL16lRYtWpCYmMioUaN45ZVX2LVrF/Xq1eORRx4hKiqK2bNn8/TTT/PZZ5/l2Mfy5cv57LPP8PDwwNXV1dQ5asGCBXz00Uf4+PjIM+NCSDl0mbg5v3BxWjhxc34h5dBlS4dkVkWe4LM4tW7dWme/f1GaWWqCxOyx6ZKSkmRsOlFqhYaG8vnnn/P555/j7u6Oj48P3t7eLF68GG9vb7Zt28bf//53bty4wcWLF2nWrJmlQ7ZKKYcuk/jNKXRapqlM2dvg1K8pVT0ftWBkhVPcE3wKC5Cx6URZ0aFDB+Li4mjbti2PPfYYlSpVokOHDtSuXZuwsDCGDBmCwWDAz8/P1C3/Qdb+kUDrPcdw3h5F6z3HWPtHQjGfRdl37ceYHMkMQKdlcu3HGMsEVAykU4gZlPQEiXD/semklSZKk86dO+f4Xf3tt98ASNqwgQYfzOeL5BTsnJ15dOLLOPbq9cD9rf0jgcknL5CamXV36eKtNCafvABA/zo1iuEMrENG4q1ClZdF0kIro6xxbDpRfiRt2EDczFmkx8aC1qTHxhI3cxZJGzY8cNt3zsSZklm21EzNO2fMO5+atbF1qlio8rJIEloZVRxj05VWMqr4g7Vr1y7P8pCQkBzvLpUWlz+Yj871krC+eZPLH8x/4LaXbqUVqlxkqR7sgrLP+Sdf2dtQPdjFMgEVA0loZZS5x6YrzR4moeU3+oK12rNnj6VDKJT0uLxbU/mV361eRftClYssVT0fxalfU1OLzNapYpnrEPIgktDKKHOPTXc/ZXVU8fIke7R5rTXjxo2jVatW9OjRg8uX/9ctOzIyksDAQLy9vQkODjaNuvHpp5/i4+ODh4cH/fv358aNG8Uer51z3rNT51d+t+mNnalsk/Ol6so2iumNzTvjtTWq6vkoztN8qT+nA87TfK0qmQHyYrW4v6NHj+pmzZqZXhC/evWq7tmzpw4LC9Naa/3ZZ5+ZXuQeOXKkHjRokM7MzNTr16/X1apV09HR0TojI0N7eXnpQ4cOaa21BvSyZcu01lq/8cYb+sUXX9Raax0YGKgPHDigtdY6Pj5eN2zYUGut9ZIlS0x1tM566Tz7pdq//vpLN23aVCcnJ+slS5boevXqmV5OL0+yX8pdu3at7tKli05PT9eXLl3Sjo6OevXq1fr27du6bdu2+vLly1prrVeuXKmfeeYZrbXWV65cMe1nxowZeuHChcUeb+J33+lfPYz6ePMWpq9fPYw68bvvCrT9mrir2nv3UV1n2yHtvfuoXhNX/v7Nyyvu82K19HIU95XfqOLffPMNkDWO3quvvmqqn9eo4oBpVHGj0XjPqOL9+vUrVEybN2/mu+++M82Zld+o4uXRzp07GTJkCLa2ttStW9c0VNLJkyc5evQoXbt2BbKmM3K+0xo6evQor732GomJiSQnJxMcHFzscWb3Zrz8wXzS4+IK1csRsnozSo9GkZskNHFfugyPKl4WJCYm8tVXX/HCCy+wY8cO5s2bl+f4e4WR39igrq6u7N279551ISEhrF+/Hg8PD8LCwtixY0eRjl9Qjr16FTiBCVEQ8gxN3FdZHlW8LEhMTDRNNWQOAQEBrFy5koyMDOLi4ti+fTsAzZs3Jz4+3pTQ0tLSOHbsGADXr1/H2dmZtLQ0li9fbrZYhChp0kIT91WWRxUvC6ZNm8bp06cxGo3Y29tTtWpVBgwYwNGjR/H29mbZsmUopYiMjGTSpEkkJydTq1YtwsLCTLcM79a3b1+2bduGu7s7zZo1IzAwEMia4XjNmjW89NJLJCUlkZ6ezssvv4yrqytvvvkmbdq0oWHDhri7u+f48CBEWSJjOYoS5+DgkGPeq6JY+0cC75yJ49KtNOpVtGd6Y+cy9Wzl7nFAd+zYQe/evTl27Bh169bF39+fuXPn0qZNGwIDA/n222+pXbs2q1at4scff+Tzzz8v0rE3ntnIgoML+CPlD+pUrcMErwn0aNzDTGcmRPG431iO0kITZZY1DoHk6+tL/fr1ATAajcTExODk5JRvh46HtfHMRkL3hHIzI+tZZVxKHKF7QgEkqYkyS56hlTJPPPEEiYmJD7VtWFgY48aNu2+dHTt2WPwlXHO1zqxxCKS7O9LY2tqSnp5u6tARFRVFVFQUR44cYfPmzUU6zoKDC0zJLNvNjJssOLigSPsVwpIkoZUymzZtwsnJqdj2XxoSmrlYwxBIuTu85OV+HToe1h8pfxSqXIiyQBLaQ4qJiaFFixaMHj0aNzc3hg4diqurK/7+/jRt2pRffvmFX375hXbt2uHp6Um7du04efIkkNWS6tevH927d6dp06Y53uNycXHhypUrpv2PHDkSg8HAgAEDTCM4ZNcBiIiIoGPHjvfEt2HDBtq0aYOnpyddunThzz//JCYmhkWLFvHBBx9gNBoJDw8nPj6e/v374+Pjg4+PD7t37y7+i2cmJTkE0t29EXfs2EHPnj0LtX1YWBixsbH3lNesWRN/f3/c3NyYMmVKnttmd+iYOnUqHh4eGI3GIn8oqVO1TqHKhSgT8nvjujR8leaRQs6ePattbW1zjITxzDPPmEbJ6N27t05KStJpaWlaa61/+ukn3a9fP6111sgXjRo10omJiTo1NVX/7W9/0+fPn9daa92wYUMdHx+vz549qwG9a9curbXWzzzzjGla+uw6Wmt94MABHRgYaNpv9ogaCQkJOjMzU2ut9aeffqonTZqktdY5prfXWushQ4bo8PBwrbXW586d0y1atCi2a2Zua+KuapcdUfqxbYdMXy47oopl1IizZ89qV1dXrbXW27dv1z169CjU9nePglJY6w5e1O3e2apdpn6v272zVa87ePGh9nO3709/r1t/2Vq7hbmZvlp/2Vp/f/r7Iu9biOKEjBRSPBo1apRjJIyvvvqKzz//nMcee4wtW7bQtm1bLly4QM2aNXFwcMgxJ1Tnzp1N4zC2atWKc+fO0aBBgxz7b9CgAf7+/kDWiBoLFy5k8uTJBYrt4sWLDBo0iLi4OG7fvk2jRo3yrLdlyxaOHz9uWr527RrXr1+nWrVqBb8QFpLd8aMkejkWtHv97Nmz2bBhA6mpqbRr145///vfrF27loiICIYOHUrlypXZu3cvlStXLtBx1x+6xPRvjpCalgHApcRUpn9zBIA+nvUe+nyyO35IL0dhTSShFUHukTCybdiwgapVq+Lj48Ozzz7LP/7xD65evZrj1mBeD/9zyz3iQ2FG1Bg/fjyTJk3iySefZMeOHYSGhuZZLzMzs1B/YEubkhoCac6cORw9epSoqKg8u9fv3r2b9u3bM27cOGbNmgVkDQv2/fffM2DAAD788EPmzZtH69Z59jbO19wfT5qSWbbUtAzm/niySAkNspKaJDBhTeQZWjEwGAwkJiayb98+0tPTqVatGmFhYYXez/nz500dAVasWJHniBpr167Nc9ukpCTq1cv6g7d06VJTee5OCN26dePDDz80LUdFRRU6zvIou3u9jY2NqXs9wPbt22nTpg3u7u5s27atyJ03YhNTC1UuRHkmCa0YtGnTBhcXF/r06cOMGTNo2rQpGRkZD94wl5YtW7J06VIMBgMJCQmMHTsWgNdff50JEybQoUMHbG1t89w2NDSUgQMH0qFDB9PAwpA1ePC6detMnUIWLlxIREQEBoOBVq1asWjRooc76XImrxb2zZs3eeGFF1izZg1Hjhzh2Wefve+YlAVR1ynvlnN+5aJsCQ0NNQ2ynZf169fneCQg7k9uOT4kFxcXjh49aloOCwszjT+olOLYsWPY2dlRp04dYmJiePPNN3nzzTeBrMFg754f7O5hm7I/6ScnJ2NjY5NngunQoQO//fbbPeV377d379707t37njrNmjUjOjqa9YcuMe3Hk8Ru3E9dz+eYPa15kW9hWbOCdK/PTl61atUiOTmZNWvWMGDAgAJvn5cpwc1zPEMDqGxvy5Tg5vfZSliL9evX07NnT1q1amXpUMoEs7TQlFLdlVInlVK/K6Wm5bFeKaUW3lkfrZTyMsdxS6sdO3ZgNBrx9PRk7dq1TJgwwdIh5ZDd0eBSYiqa/3U0WH/okqVDK7UK0r3eycmJZ599Fnd3d/r06YOPj49pXUhICM8//zxGo5HU1ILfLuzjWY93+rlTz6kyCqjnVJl3+rnLh48y7O2336Z58+Z06dLF9CpPXpOs7tmzh++++44pU6ZgNBo5ffq0RSZjLUuKPJajUsoW+A3oClwEDgBDtNbH76rzBDAeeAJoAyzQWrd50L7L2liOv4ZvJ3zlF1y/eoVqNWvRYfAIWnYIsnRY9/Cfs41LeTyDqedUmd3TOuWxRdHdPWZhQcyaNYuAgAC6dOlSLPGUhN/2/8Heb0+TnHALhxoVadu7Cc3ayHte5VlkZCQhISHs37+f9PR0vLy8eP7553nmmWeoWbMmAK+99hqPPfYY48ePJyQkhJ49e5pa+levXs2zXnlS3GM5+gK/a63P3DnYSqA3cPeN397AF3feIdinlHJSSjlrrcvuGEW5/Bq+nc2LPyT99i0Arl+JZ/PirM4WpS2plYWOBrNnz7Z0CEXy2/4/2L78BOm3s3qjJifcYvvyEwCS1Mqx8PBw+vbtS5UqVQB48skngYJPsmqJyVjLEnPccqwHXLhr+eKdssLWAUApNUYpFaGUioiPjzdDeCUjfOUXpmSWLf32LcJXfmGhiPJnqY4G6enp94x8EhkZSWBgIN7e3gQHBxMXl/UZJyQkxPRM0sXFhddffx0vLy/c3d05cSIrMcTHx9O1a1e8vLx47rnnaNiwIVeuXCElJYUePXrg4eGBm5ubaXqakrT329OmZJYt/XYme789XeKxiNIlrwlYQ0JC+PDDDzly5Aivv/56vp2JClqvvDJHQstrOuPc9zELUierUOvFWuvWWuvWtWvXLnJwJeX61SuFKrekKcHNqWyfs3dkSXQ0OHnyJGPGjCE6Oprq1avz0UcfMX78eNasWUNkZCSjRo1ixowZeW5bq1YtDh48yNixY029wt544w06derEwYMH6du3L+fPnwfghx9+oG7duhw+fJijR4/SvXv3Yj2vvCQn3CpUuSgfAgICWLduHampqVy/fp0NGzYA+U+ymrszkUzGen/mSGgXgbuHuKgP5B60riB1yrRqNWsVqtySLNXRIPfIJz/++KNpWhSj0chbb73FxYsX89y2X79+AHh7e5t6gu7atYvBgwcD0L17dx555BEA3N3d2bJlC1OnTiU8PNw0IktJcqhRsVDlonzw8vJi0KBBGI1G+vfvT4cOHQBMk6x27dqVFi1amOoPHjyYuXPn4unpyenTp/OtJ7KY4xnaAaCpUqoRcAkYDDydq853wLg7z9faAEnW9PwMoMPgETmeoQHYVahIh8EjLBhV/vp41ivxnnK5b7VUq1YNV1dX08vj95P93tfdo6rk16GpWbNmREZGsmnTJqZPn063bt1Mo3eUlLa9m+R4hgZgV8GGtr2blGgcovSZMWNGnncist8zvZu/v7/pPbSkDRvosnoNHStVxs7Glke7dcOxV69ij7csKXILTWudDowDfgR+Bb7WWh9TSj2vlHr+TrVNwBngd+BT4IWiHre0adkhiG5jxlGtVm1Qimq1atNtzLhS1yHEknKPfOLn51ekaVHat2/P119/DcDmzZv566+/AIiNjaVKlSoMGzaMyZMnc/DgQTOfyYM1a1OHoKEtTC0yhxoVCRraQjqEiIeStGEDcTNnkR4bC1qTHhtL3MxZJN25ZSmymOXFaq31JrKS1t1li+76WQMvmuNYpVnLDkGSwO4je+ST5557jqZNmzJ+/HiCg4N56aWXSEpKIj09nZdffhlXV9cC7e/1119nyJAhrFq1isDAQJydnalWrRo7duxgypQp2NjYYG9vzyeffFLMZ5a3Zm3qSAITZnH5g/noXB1A9M2bXP5gvrTS7lLk99CKU1l7D02UrFu3bmFra4udnR179+5l7Nix/Pzmm1z+YD7pcXHYOTvz6MSX5T+8KPN+bdkK8vpbrRQtfy1fQ2MV93toQljE+fPneeqpp8jMzKRChQp8MGIEcTNnmT7JZt+WASSpiTLNztk563ZjHuXif2RwYlFmNW3alEOHDnH48GEOHDhA/e835ntbRpQvDzMYeGn26MSXUZUq5ShTlSrx6MSXLRNQKSUJTViN9Li8O87mVy7Krj59+uDt7Y2rqyuLFy8GwMHBgVmzZtGmTRv27t3LsmXL8PX1xWg08txzz5XpJOfYqxfOb87Grm5dUAq7unVxfnO23HnIRRKasBr53X6R2zLW5/PPPycyMpKIiAgWLlzI1atXSUlJwc3Njf3791OzZk1WrVrF7t27iYqKwtbWtsy/iOzYqxdNt22l5a/HabptqySzPMgzNGE1Hp34co5naCC3ZazVwoULWbduHQAXLlzg1KlT2Nra0r9/fwC2bt1KZGSkacaD1NRUHn30UYvFK0qGJDRhNbI/sUovR+u2Y8cOtmzZwt69e6lSpQodO3bk5s2bVKpUyTThrdaakSNH8s4771g4WlGSJKEJq+LYq5ckMCuXlJTEI488QpUqVThx4gT79u27p07nzp3p3bs3EydO5NFHHyUhIYHr16/TsGFDC0QsSoo8QxNClCndu3cnPT0dg8HAzJkz8fPzu6dOq1ateOutt+jWrRsGg4GuXbuaZnIQ1kterBZCWBWZWNW6yYvVQohyQSZWLd/klqMQwmrIxKrlmyQ0IYTVkIlVyzdJaEIIqyETq5ZvktCEEFajbe8m2FXI+WdNJla1jMTERD7++OMSPaYkNCGE1ZCJVUsPSyQ06eUohLAqMrFq6TBt2jROnz6N0Wika9euAPz3v/9FKcVrr73GoEGDzH5MaaEJIYQwuzlz5tCkSROioqLw8/MjKiqKw4cPs2XLFqZMmVIsL7pLQhNCCFGsdu3axZAhQ7C1teWxxx4jMDCQAwcOmP04ktCEEEIUq5IakUoSmhClXFRUFJs2bSp0ve+++445c+aYPR4HBwez71NYn2rVqnH9+nUAAgICWLVqFRkZGcTHx7Nz5058fX3NfkxJaMCiRYv44osvHrguLCyM2NjYkgxNiIdOaE8++STTpk0rztCEyFfNmjXx9/fHzc2NvXv3YjAY8PDwoFOnTrz33nvUqVMMHXe01qX2y9vbW1tSWlpajuXAwEB94MABC0UjLGXp0qXa3d1dGwwGPWzYMB0TE6M7deqk3d3ddadOnfS5c+e01lqPHDlSP//887pjx466UaNGeseOHfqZZ57RLVq00CNHjjTtr2rVqnrSpEna09NTd+rUSV++fFlrnfP3Kz4+Xjds2FDfunVLN2jQQNeqVUt7eHjolStX6v379+u2bdtqo9Go27Ztq0+cOJFnvSVLlugXX3xRa63vG/P48eN127ZtdaNGjfTq1au11lpfv35dd+rUSXt6emo3Nze9fv36HPELUVDHd27T/34hRM8b1FP/+4UQfXzntiLtD4jQ+eQMiyet+30VJaElJyfrJ554QhsMBu3q6qpXrlypGzZsqF999VXt4+OjfXx89KlTp7TWWr/++ut67ty5WuusPyrTp0/XAQEBet68eaZ1q1ev1lWrVtXNmjXTHh4e+saNG3rq1Km6ZcuW2t3dXb/yyisPHasovY4ePaqbNWum4+PjtdZaX716Vffs2VOHhYVprbX+7LPPdO/evbXWWclh0KBBOjMzU69fv15Xq1ZNR0dH64yMDO3l5aUPHTqktdYa0MuWLdNaa/3GG2+Ykk5eCU1rnSMxaa11UlKS6cPWTz/9pPv165dnvbuX7xfzgAEDdEZGhj527Jhu0qSJ1jrrw1xSUpIpliZNmujMzEyttSQ0UXDHd27T84f10/Oe6mH6mj+sX5GS2v0SmtXecvzhhx+oW7cuhw8f5ujRo3Tv3h2A6tWr88svvzBu3DhefvnlPLdNTEzk559/5pVXXjGVDRgwgNatW7N8+XKioqJITU1l3bp1HDt2jOjoaF577bWSOC1RwrZt28aAAQOoVasWADVq1GDv3r08/fTTAAwfPpxdu3aZ6vfq1QulFO7u7jz22GO4u7tjY2ODq6srMTExANjY2JjewRk2bFiO7QsiKSmJgQMH4ubmxsSJEzl27NgDt7lfzH369MHGxoZWrVrx559/AlkfdP/5z39iMBjo0qULly5dMq0ToqDCV35B+u2c42im375F+Mq8H/EUldUmNHd3d7Zs2cLUqVMJDw/H0dERgCFDhpi+7927N89tC/LCX/Xq1alUqRKjR4/mm2++oUqVKuYLXpQaWmuUUvetc/f6ihWzRqiwsbEx/Zy9nJ6eft/t7ezsyMzMGin+5s2b+R5v5syZBAUFcfToUTZs2HDfuoWJGf7XG2358uXEx8cTGRlJVFQUjz322EMdR5Rv169eKVR5UVltQmvWrBmRkZG4u7szffp0Zs+eDeT8j5zfH6qqVas+cP92dnb88ssv9O/fn/Xr15tagMK6dO7cma+//pqrV68CkJCQQLt27Vi5ciWQ9Ye/ffv2hdpnZmYma9asAeCrr74ybe/i4mJ6Nyd7PeTsLQZZLbR69eoBWR2V7q6XlJSU5zELG3NSUhKPPvoo9vb2bN++nXPnzhXqHIUAqFazVqHKi8pqh76KjY2lRo0aDBs2DAcHB9N//FWrVjFt2jRWrVpF27ZtC7XPu/+wJCcnc+PGDZ544gn8/Pz4+9//bu5TEKWAq6srM2bMIDAwEFtbWzw9PVm4cCGjRo1i7ty51K5dmyVLlhRoX5cvX6ZFixbY2dkxYcIExo4di8Fg4OzZs9SuXZtDhw6xefNmFixYQGJiIomJiUydOpWpU6cyZ84cGjRoQHp6Os7OzowaNYpx48YxevRorly5wqRJkzhw4ACnTp2iWbNmANy6dYvbt28zfvx4Fi5cyOOPP864ceOwt7encuXKfPjhhxw7doyff/6ZefPm5eghOXToUHr16kXr1q0xGo20aNGiWK6vsG4dBo9g8+IPc9x2tKtQkQ6DRxTL8aw2oR05coQpU6ZgY2ODvb09n3zyCQMGDODWrVu0adOGzMxMVqxYUah9hoSE8Pzzz1O5cmX++9//0rt3b27evInWmg8++KCYzkRY2siRIxk5cmSOsm3btt1T7+7WkouLC0ePHs2xLiYmhhdffJFKlSrx559/MmrUKFq1asWHH35IpUqViIyMJDY2Fj8/P44dO8YjjzxCt27d2LlzJ99++y3t2rXj8OHDVKtWjU6dOuHh4cGbb77JhQsX+O2339ixYwe2trZcu3aNKlWqYGdnx5YtW/jnP//J2rVrmTp1Km+99RaHDh3i5s2b/P3vf+fdd9/l+eefZ+LEiXzxxRckJycDUKtWLfbu3UvKoctc+zGGjFojsV15mZTgKqY6QjxIyw5BQNaztOtXr1CtZi06DB5hKjc3q01owcHBBAcH31P+4osv8vrrr+coCw0NNf28Y8eOfNf179+f/v37E/fHt5w5/RTvzEmgUkVnGjeZjHOd3uYMX1ipBg0akJCQAGR1CFm4cCHwv+e2Bw4coGPHjtSuXRvIaint3LkTgMDAQGrUqAHAwIED+e2330z7HThwILa2tkDW7cKRI0dy6tQplFKkpaWZ6gUFBVGtWjWqVauGo6MjvXr1ArKeOUdHR+eINeXQZRK/OYVOy3qul5F4i8RvTgFQ1fNRM14VYc1adggqtgSWm9U+QysucX98y4kTM7h5KxbQ3LwVy4kTM4j741tLhybKAKVUjhZO9nPc7Oe22Z0ycsuvPNvdz33v12kkd0eVuzux5O60cu3HGFMyM8WRlsm1H2PuG4sQllKuElpMTIyp+/XDOnN6HpmZqTnKMjNTOXN6XpH2K8qH8+fPm3rXrlix4p7OGW3atOHnn3/mypUrZGRksGLFCgIDA/H19eXnn3/mr7/+Ij09nbVr1+Z7jPw6jRRWRuKtQpULYWnlKqGZw81beU95kF+5EHdr2bIlS5cuxWAwkJCQwNixY3Osd3Z25p133iEoKAgPDw+8vLzo3bs39erV45///Cdt2rShS5cutGrVyvQqSm6vvvoq06dPx9/fn4yMjIeO1dapYqHKhbA09aBbGZbUunVrHRERYekwcti9u8Od2405VapYF3//cAtEJMqKmJgYevbsmaOzSGEkJyfj4OBAeno6ffv2ZdSoUfTt2/eh9rX+0CXm/niS2MRU6jpVZkpwc/p41stRJ/czNABlb4NTv6byDE1YjFIqUmvdOq91RWqhKaVqKKV+UkqduvP9kXzqfa6UuqyUerj/yaVI4yaTsbGpnKPMxqYyjZtMtlBEorwIDQ3FaDTi5uZGo0aN6NOnz0PtZ/2hS0z/5giXElPRwKXEVKZ/c4T1hy7lqFfV81Gc+jU1tchsnSpKMhOlWpFaaEqp94AErfUcpdQ04BGt9dQ86gUAycAXWmu3gu6/NLbQgDu9HOdx81ac9HIUZY7/nG1cSky9p7yeU2V2T+tkgYiEKLj7tdCK2m2/N9Dxzs9LgR3APQlNa71TKeVSxGOVGs51eksCE2VWbB7J7H7lQpQVRe0U8pjWOg7gzvci34tQSo1RSkUopSLi4+OLujshRC51nSoXqlyIsuKBCU0ptUUpdTSPr2JpomitF2utW2utW2e/XCqEMJ8pwc2pbG+bo6yyvS1TgptbKCIhzOOBtxy11l3yW6eU+lMp5ay1jlNKOQOXzRqdEMLssnszPqiXoxBlTVGfoX0HjATm3Pkuw2UIUQb08awnCUxYnaI+Q5sDdFVKnQK63llGKVVXKWUaulsptQLYCzRXSl1USv2jiMcVQgghcihSC01rfRXonEd5LPDEXctDinIcIYQQ4kFk6CshhBBWQRKaKBE7duxgz549lg5D5NKuXbsH1nFxceHKlSsF3mdYWBjjxo277/FiYmL46quvCrzPknR3/KGhocybJwOPlxWS0ESh5Z5mpCAkoZVOJf1vkn280pzQRNklCU3k6YsvvsBgMODh4cHw4cMJCQlh0qRJBAUFMXXqVE6fPk337t3x9vamQ4cOnDhxAoANGzbQpk0bPD096dKlC3/++ScxMTEsWrSIDz74AKPRSHh4OPHx8fTv3x8fHx98fHzYvXu3hc+4fHJwcACyPnB07NiRAQMG0KJFC4YOHZpjDrZ//etfeHl54e7ubvq3/uWXX2jXrh2enp60a9eOkydPmupfuHCB7t2707x5c9544417jjdt2jTCw8MxGo1mne09JSWFHj164OHhgZubG6tWrcLFxYWpU6fi6+uLr68vv//+O0ChfwcXLlxIq1atMBgMDB482GwxCzPSWpfaL29vby1K3tGjR3WzZs10fHy81lrrq1ev6pEjR+oePXro9PR0rbXWnTp10r/99pvWWut9+/bpoKAgrbXWCQkJOjMzU2ut9aeffqonTZqktdb69ddf13PnzjUdY8iQITo8PFxrrfW5c+d0ixYtSubkRA5Vq1bVWmu9fft2Xb16dX3hwgWdkZGh/fz8TP8+DRs21AsXLtRaa/3RRx/pf/zjH1prrZOSknRaWprWWuuffvpJ9+vXT2ut9ZIlS3SdOnX0lStX9I0bN7Srq6s+cODAPcfr0aOH2c9nzZo1evTo0ablxMRE3bBhQ/3WW29prbVeunSp6bj5/Q4uWbJEv/jii1rrnL+3zs7O+ubNm1prrf/66y+zxy4KBojQ+eSMor6HJqzQtm3bGDBggGky1Bo1agAwcOBAbG1tSU5OZs+ePQwcONC0za1bWZM+Xrx4kUGDBhEXF8ft27dp1KhRnsfYsmULx48fNy1fu3aN69evU61ateI6LfEAvr6+1K9fHwCj0UhMTIxpAtJ+/foB4O3tzTfffANkTSQ6cuRITp06hVKKtLQ00766du1KzZo1Tdvu2rWL1q3zHE/WrNzd3Zk8eTJTp06lZ8+edOjQAYAhQ4aYvk+cOBHI/3cwPwaDgaFDh9KnT5+HnulAFC9JaOIeWmuUUveUV61aFYDMzEycnJyIioq6p8748eOZNGkSTz75JDt27CA0NDTPY2RmZrJ3714qV5bxA0uLihX/N3Gnra1tjmel2evuLp85cyZBQUGsW7eOmJgYOnbsaKqf+/cnr9+n4tCsWTMiIyPZtGkT06dPp1u3bvccP/vnwv4Obty4kZ07d/Ldd9/x5ptvcuzYMezs5E9oaSLP0EqZ7GcMRRUVFcWmTZseXDEPnTt35uuvv+bq1asAJCQk5FhfvXp1GjVqxOrVq4GsBHj48GEg61N7vXpZI1AsXbrUtE21atVyfPrt1q0bH374YY54Rdly9791WFhYjnU//fQTCQkJpKamsn79evz9/XOsz/37YC6xsbFUqVKFYcOGMXnyZA4ePAjAqlWrTN/btm0LFO53MDMzkwsXLhAUFMR7771HYmIiycnJZo9fFI0kNCtVlITm6urKjBkzCAwMxMPDg0mTJt1TZ/ny5Xz22Wd4eHjg6urKt99mjXoWGhrKwIED6dChg+mWJUCvXr1Yt26dqVPIwoULiYiIwGAw0KpVKxYtWkRiYiIff/wxkNVJoWfPnnnGN3r06By3ioRlvPrqq0yfPh1/f38yMjJyrGvfvj3Dhw/HaDTSv3//e243GgwG7Ozs8PDwMGunkCNHjuDr64vRaOTtt9/mtddeA7Juibdp04YFCxaYjpfX72B+MjIyGDZsGO7u7nh6ejJx4kScnJzMFrcwk/werpWGL2vvFNK7d2/t5eWlW7Vqpf/9739rrbMemk+aNEl7enrqTp066cuXL2uttT506JBu06aNdnd313369NEJCQlaa60DAwNND9zj4+N1w4YN9a1bt3SDBg10rVq1tIeHh165cmWR4sx+kH8/H3zwgU5JSTEtP/744/k+OP/+9Pe66+qu2j3MXXdd3VV/f/p7rbXWZ8+e1a6urlrr4us0ICzj+M5t+t8vhOh5g3rqf78Qoo/v3FZix27YsKGpg9PDyO/3VVgG9+kUIi00C/r888+JjIwkIiKChQsXcvXqVVJSUvDy8uLgwYMEBgaaujyPGDGCd999l+joaNzd3XN0hc6tQoUKzJ49m0GDBhEVFcWgQYOK/Vzmz5/PjRs3TMubNm3K8xPsxjMbCd0TSlxKHBpNXEocoXtC2XhmI9OmTeP06dMYjUamTJlCcnJynt3IO3bsSPZM5g4ODsyYMQMPDw/8/Pz4888/ATh9+jR+fn74+Pgwa9Ys063cuLg4AgICMBqNuLm5ER4eXsxXRvwavp3Niz/k+pV40JrrV+LZvPhDfg3fbunQHuh+v6+i9JGEZkELFy40/SG+cOECp06dwsbGxpSAhg0bxq5du0hKSiIxMZHAwEAARo4cyc6dOwt0jGXLlpluwTz33HN89NFHvPrqq6b1YWFhjB8/HoD3338fNzc33NzcmD9//j37yn0bcNy4cYSFhbFw4UJiY2MJCgoiKCgIyDm6xN37nfTmJG5m3OR2/G1OTT/Fpc8vcWTqEUb0HUFoaChNmjQhKiqKuXPncujQIebPn8/x48c5c+ZMnu8JpaSk4Ofnx+HDhwkICODTTz8FYMKECUyYMIEDBw5Qt25dU/2vvvqK4OBgoqKiOHz4MEajsUDXUTy88JVfkH77Vo6y9Nu3CF/5RYkcPyYmJsft78JYcHABNzNu5ii7mXGTBQcXmCM0YWaS0Cxkx44dbNmyhb1793L48GE8PT25efPmPfUe1DvMzs6OzMxMgHu2T0hIYNWqVezevZuoqChsbW1xcHAwdbuGrIfkgwYNIjIykiVLlrB//3727dvHp59+yqFDhwp0Li+99BJ169Zl+/btbN+e81N37v2e23yO1HOpANz68xY1Oteg6f81JaNiBv/9739zbJvdjdzGxsbUjTy3ChUqmJKst7e3qc7evXtNrxU8/fTTpvo+Pj4sWbKE0NBQjhw5Iq8JlIDrV/MeNiu/8tLkj5Q/ClUuLEsSmoUkJSXxyCOPUKVKFU6cOMG+ffuArN5Ua9asAbJaE+3bt8fR0ZFHHnnEdHvsyy+/NLXWXFxciIyMBDBtB1m9yE6fPk1kZCQ+Pj4YjUa2bt3K2bNnady4Mfv27ePq1aucPHkSf39/du3aRd++falatSoODg7069fPLLfjcu+3btu63Pgt69ZkhdoVqNwwq8t07Wa1uXjxYo5t79eNPJu9vb0p6edX524BAQHs3LmTevXqMXz4cL74omRaCeVZtZp5t47yKy9N6lStU6hyYVmS0Cyke/fupKenYzAYmDlzJn5+fkDWu17Hjh3D29ubbdu2MWvWLCCrC/yUKVMwGAxERUWZyidPnswnn3xCu3btcgwgGxQURFxcHBkZGUyfPp2oqChOnjxJaGgogwYN4uuvv2bt2rX07dsXpVSOYY7yc3drEO5tEeYl93596/hip7Le3VF2WYmokm0lAhoEYGtra7au3H5+fqxduxaAlStXmsrPnTvHo48+yrPPPss//vEPU7duUXw6DB6BXYWKOcrsKlSkw+ARFoqo4CZ4TaCSbaUcZZVsKzHBa4KFIhL3I28FWkjFihXvucUGmN5tefPNN3OUG41GUyvubi1atCA6OhqA9Ycusd2hE42mbaSuU2WmfLCUhdPGmJ5rJSQkcP36dfr168fbb79Nw4YNeffdd4GslktISAjTpk1Da826dev48ssvcxyrYcOGHD9+nFu3bnHz5k22bt1qGkki+72i3M8qcu/36I6jTH5nMqsvrOYc53Cu6swErwn8+sevJCcn4+/vj5ubG5UrV+axxx57mEsLZHVSGTZsGP/v//0/evTogaOjI5B1q3fu3LnY29vj4OAgLbQS0LJD1u9f+MovuH71CtVq1qLD4BGm8tKsR+MeQNaztD9S/qBO1TpM8JpgKheliyQ0K7H+0CWmf3OE1LSs94EuJabycZQtvf8xiW7dupGZmYm9vT0fffQRDRs2pFWrVhw/fhxfX18AvLy8CAkJMS2PHj0aT0/PHMdo0KABTz31FAaDgaZNm+ZYP2bMGB5//HGcnZ1zPEfLa78v9XqJJ2OepOfHPdk8YDMAv/IrQL4jsN/9AuyOHTtMP9/9cuuAAQMYMGAAAPXq1WPfvn0opVi5ciWtW7dm45mNLK+6HJspNtSuWpsJXhPyHZpLmFfLDkFlIoHlpUfjHgVOYKGhoTg4OHDt2jUCAgLo0qVLkY4dFRVFbGwsTzzxxIMrC1RBbjVZSuvWrXV292xxf/5ztnEpMfWe8npOldk9rZMFIrq/3/b/wd5vT5OccAuHGhVp27sJzdqY77lEeHg448aNQ2uNk5MTw0OHszh2cY4ea5VsKxHaLlQ+bQuzyU5okydPznN9RkYGtra2Bd5fWFgYEREROT7QlXdKqUitdZ4Dg8ozNCsRm0cyu1+5Jf22/w+2Lz9BckJWV+7khFtsX36C3/abr+dYhw4dOHz4MNHR0ezcuZPVCaul+7UoFm+//TbNmzenS5cupil0QkJCTJ20XFxcmD17Nu3bt2f16tVs3ryZtm3b4uXlxcCBA013GQ4cOEC7du3w8PDA19eXpKQkZs2axapVqzAajabhu0T+5JajlajrVDnPFlpdp9I3+O/eb0+TfjszR1n67Uz2fnvarK20u0n3a1EcIiMjWblyJYcOHSI9PR0vLy+8vb3vqVepUiV27drFlStX6NevH1u2bKFq1aq8++67vP/++0ybNo1BgwaxatUqfHx8uHbtGlWqVGH27NnSQisESWhWYkpw8xzP0AAq29syJbi5BaPKW3bLrKDl5lCnah3iUuLyLBfiYYWHh9O3b1+qVKkCwJNPPplnvezBEvbt28fx48dNgzXfvn2btm3bcvLkSZydnfHx8QGyBgAXhScJzUr08cwa9XzujyeJTUzN6uUY3NxUXpo41KiYZ/JyqFExj9rmMcFrAqF7Qu95hibdr0VRFWRqnOypl7TWdO3alRUrVuRYHx0dXWJT7FgzeYZmRfp41mP3tE6cndOD3dM6lcpkBtC2dxPsKuT81bOrYEPb3k2K7Zg9GvcgtF0ozlWdUSicqzpLhxBRZAEBAaxbt47U1FSuX7/Ohg0b7lvfz8+P3bt38/vvvwNw48YNfvvtN1q0aEFsbCwHDhwA4Pr166SnpxfbNDvWSlpoosRlPycrzl6OeSlM92shCsLLy4tBgwZhNBpp2LChaYbs/NSuXZuwsDCGDBlimuX9rbfeolmzZqxatYrx48eTmppK5cqV2bJlC0FBQcyZMwej0cj06dNLZKDxsky67QshhCgz7tdtX1poQghRihT3O5rWTBKaEEKUEtnvaGa/1pL9jiYgSa0ApFOIEEKUEvd7R1M8mCQ0IYQoJSzxjqY1kYQmhBClRH7vYhbnO5rWRBKaEEKUEpZ4R9OaSEITopxo166dpUMQD9CsTR2ChrYwtcgcalQkaGgL6RBSQNLLUQgzK+wUIbmlp6djZ2f+/5p79uwx+z6F+TVrU0cS2EOSFpoQhRATE0OLFi0YOXIkBoOBAQMGcOPGjXumCFmxYgXu7u64ubkxdepU0/afffYZzZo1o2PHjjz77LOMGzcOyJpuZNKkSQQFBTF16lR++eUX2rVrh6enJ+3atTNNSxIWFkafPn3o1asXjRo14sMPP+T999/H09MTPz8/EhISAFi4cCGtWrXCYDAwePBgABwcHICsCVI7duzIgAEDaNGiBUOHDqU0D7AgRIFprR/6C6gB/AScuvP9kTzqNAC2A78Cx4AJBd2/t7e3FqI0OXv2rAb0rl27tNZaP/PMM3ru3Lm6YcOG+t1339Vaa33p0iXdoEEDffnyZZ2WlqaDgoL0unXr9KVLl3TDhg311atX9e3bt3X79u31iy++qLXWeuTIkbpHjx46PT1da611UlKSTktL01pr/dNPP+l+/fpprbVesmSJbtKkib527Zq+fPmyrl69uv7kk0+01lq//PLL+oMPPtBaa+3s7Kxv3ryptdb6r7/+0lprXbVqVa211tu3b9fVq1fXFy5c0BkZGdrPz0+Hh4cX85UTwjyACJ1PzihqC20asFVr3RTYemc5t3TgFa11S8APeFEp1aqIxxXCYho0aGCa/mPYsGHs2rUL+N8UIQcOHKBjx47Url0bOzs7hg4dys6dO/nll18IDAykRo0a2NvbM3DgwBz7HThwoOlWZVJSEgMHDsTNzY2JEydy7NgxU72goCCqVatG7dq1cXR0pFevXgC4u7sTExMDgMFgYOjQoSxbtizP25e+vr7Ur18fGxsbjEajaTshyrKiJrTewNI7Py8F+uSuoLWO01ofvPPzdbJaaqVzGHghCiD3NB/Zy3dPEZKX/MqzZW8PMHPmTIKCgjh69CgbNmzg5s3/TXtTseL/unDb2NiYlm1sbEhPTwdg48aNvPjii0RGRuLt7W0qz2sftra296wXoiwqakJ7TGsdB1mJC3j0fpWVUi6AJ7D/PnXGKKUilFIR8fHxRQxPCPM7f/48e/fuBWDFihW0b98+x/o2bdrw888/c+XKFTIyMlixYgWBgYH4+vry888/89dff5Gens7atWvzPUZSUhL16mV97gsLCytUfJmZmVy4cIGgoCDee+89EhMTSU5OLtxJClEGPTChKaW2KKWO5vHVuzAHUko5AGuBl7XW1/Krp7VerLVurbVuXbt27cIcQogS0bJlS5YuXYrBYCAhIYGxY8fmWO/s7Mw777xDUFAQHh4eeHl50bt3b+rVq8c///lP2rRpQ5cuXWjVqhWOjo55HuPVV19l+vTp+Pv7k5GRkWed/GRkZDBs2DDc3d3x9PRk4sSJODk5PezpClFmFGn6GKXUSaCj1jpOKeUM7NBaN8+jnj3wPfCj1vr9gu5fpo8RpU1MTAw9e/bk6NGjD7V9cnIyDg4OpKen07dvX0aNGkXfvn3NFl/Shg1c/mA+6XFx2Dk78+jEl3G884wN4Nfw7YSv/ILrV69QrWYtOgweQcsOQWY7vhDF7X7TxxT1luN3wMg7P48Evs3j4Ar4DPi1MMlMCGsUGhqK0WjEzc2NRo0a0adPH7PtO2nDBuJmziI9Nha0Jj02lriZs0i6M4vyr+Hb2bz4Q65fiQetuX4lns2LP+TX8O1mi0EISypqC60m8DXwN+A8MFBrnaCUqgv8R2v9hFKqPRAOHAGyh5H+p9Z604P2Ly00IQruVKfOWcksF7u6dWm6bSuLX3wmK5nlUq1WbcZ8tKQkQhSiyIptgk+t9VWgcx7lscATd37eBajcdYQQ5pUeF3ff8utXr+S5Pr9yIcoaGSlECCth5+x83/JqNWvluT6/ciHKGkloQliJRye+jKpUKUeZqlSJRye+DECHwSOwq5BzGhK7ChXpMHhESYUoRLGSwYmFsBLZvRnz6+WY3ZtRejkKa1WkTiHFrUmTJrpChQrUqVOH7du3M2TIEI4dO8YzzzzDxIkTC7yfxMREvvrqK1544YVijFYIIURxu1+nkFKd0BwdHfX69esJCgrijz/+oE2bNpw7d67Q+ynqu0NCCCFKh+J8D81slFLDlFK/KKWilFL/Vkq9npyczPPPP8+UKVPo1q0bly9fxmg0Eh4ezunTp+nevTve3t506NCBEydOAPDnn3/St29fPDw88PDwYM+ePUybNo3Tp09jNBqZMmWKhc9UCCFEschvGP6S/AJaAhsA+zvLHwMjHBwc9IEDB7TWWdN2uLq6mqYQ6NSpk/7tt9+01lrv27dPBwUFaa21fuqpp0xTaKSnp+vExMR7thVCCFE2cZ/pY0pLp5DOgDdw4M7I5ZWBy/lVTk5OZs+ePTmm37h16xYA27Zt44svvgCyRhF3dHTkr7/+Kr7IhRBClAqlJaEpYKnWevrdhdWqVXs9r8qZmZk4OTkRFRVVErEJIYQoA0rLM7StwACl1KMASqkaSqmG+VWuXr06jRo1YvXq1UDWbdPDhw8D0LlzZz755BMga9Txa9euUa1aNa5fv17c5yCEEMKCSkVC01ofB14DNiulooGfgLyHPbhj+fLlfPbZZ3h4eODq6sq332aNi7xgwQK2b9+Ou7s73t7eHDt2jJo1a+Lv74+bm5t0ChFCCCtVqrvtF2Vw4pRDl7n2YwwZibewdapI9WAXqnred/5RIYQQpVyxDU5cWqUcukziN6fQaVmD+2ck3iLxm1MAktSEEMJKlYpbjuZ27ccYUzLLptMyufZjjGUCEkIIUeysMqFlJN4qVLkQQoiyzyoTmq1TxUKVCyGEKPusMqFVD3ZB2ec8NWVvQ/VgF8sEJISwqPnz53Pjxo1Cb+fg4FAM0YjiYpUJrarnozj1a2pqkdk6VcSpX1PpECJEOfWwCU2ULVbZyxGykpokMCHKn5SUFJ566ikuXrxIRkYGAwcOJDY2lqCgIGrVqsX27dtxcHAgOTkZgDVr1vD9998TFhbG2bNnefrpp0lPT6d79+6mfQ4fPpwBAwbQu3dvAIYOHcqgQYN48sknLXKOIm9W2UITQpRfP/zwA3Xr1uXw4cMcPXqUl19+mbp167J9+3a2b99+320nTJjA2LFjOXDgAHXq1DGVjx49miVLlgCQlJTEnj17eOKJJ4r1PEThSUITQlgVd3d3tmzZwtSpUwkPD8fR0bHA2+7evZshQ4YAWa2ybIGBgfz+++9cvnyZFStW0L9/f+zsrPYGV5kl/yJCCKvSrFkzIiMj2bRpE9OnT6dbt2731LkzqwcAN2/ezHfd3YYPH87y5ctZuXIln3/+uXmDFmYhLTQhhFWJjY2lSpUqDBs2jMmTJ3Pw4MF7Bih/7LHH+PXXX8nMzGTdunWmcn9/f1auXAlkjRd7t5CQEObPnw+Aq6tr8Z+IKDRpoQkhrMqRI0eYMmUKNjY22Nvb88knn7B3714ef/xxnJ2d2b59O3PmzKFnz540aNAANzc3UweRBQsW8PTTT7NgwQL69++fY7+PPfYYLVu2pE+fPhY4K1EQVjs4sRBCmEX017B1NjeuXMD936kc/HYxjv4hlo6q3Lrf4MRyy1EIIfIT/TVseIkth87S4sPrjG9tg+OOaVnlotSRW45CCJGfrbMhLZUuje04P7FaVllaala54SnLxibuIS00IYTIT9LFwpULi5KEJoQQ+XGsX7hyYVGS0IQQIj+dZ4F95Zxl9pWzykWpIwlNCCHyY3gKei0ExwaAyvrea6E8PyulpFOIEELcj+EpSWBlhLTQhBBCWAVJaEIIIaxCkRKaUqqGUuonpdSpO98fyaNOJaXUL0qpw0qpY0qpN4pyTFH6LFy4kJYtWzJ06FBLhyKEKMeK2kKbBmzVWjcFtt5Zzu0W0Elr7QEYge5KKb8iHleUIh9//DGbNm26ZzBXIYQoSUVNaL2BpXd+Xgr0yV1BZ0m+s2h/56v0DiAp7uv999/Hzc0NNzc35s+fz/PPP8+ZM2d48skn+eCDDywdnhCiHCtqL8fHtNZxAFrrOKXUo3lVUkrZApHA34GPtNb789uhUmoMMAbgb3/7WxHDE+YUGRnJkiVL2L9/P1pr2rRpw7Jly/jhhx/Yvn07tWrVsnSIQohy7IEJTSm1BaiTx6oZBT2I1joDMCqlnIB1Sik3rfXRfOouBhZD1mj7BT2GKH67du2ib9++VK1aFYB+/foRHh5u4aiEECLLAxOa1rpLfuuUUn8qpZzvtM6cgcsP2FeiUmoH0B3IM6GJ0qs0TzUkhBBFfYb2HTDyzs8jgW9zV1BK1b7TMkMpVRnoApwo4nGFBQQEBLB+/Xpu3LhBSkoK69ato0OHDpYOSwghgKI/Q5sDfK2U+gdwHhgIoJSqC/xHa/0E4AwsvfMczQb4Wmv9fRGPKyzAy8uLkJAQfH19ARg9ejSenp4WjkoIIbLIjNVCCCHKDJmxWphX9NfwgRuEOmV9l9l7hRClgAxOLArnzpT0pKVmLSddyFoGGcBVCGFR0kIThXNnSvocsqekF0IIC5KEJgpHpqQXQpRSktBE4ciU9EKIUkoSmigcC0xJHxsby4ABA4pt/0II6yAJTRSOBaakr1u3LmvWrCnUNhkZGcUUjRCitJKEJgrP8BRMPAqhiVnfH5DMvvjiCwwGAx4eHgwfPpxz587RuXNnDAYDnTt35vz58wCEhITw0ksv0a5dOxo3bmxKYjExMbi5uQEQFhbGuHHjTPvu2bMnO3bsAMDBwYFZs2bRpk0b9u7dy7Jly/D19cVoNPLcc89JkhPCyklCE8Xq2LFjvP3222zbto3Dhw+zYMECxo0bx4gRI4iOjmbo0KG89NJLpvpxcXHs2rWL77//nmnT8ppeL38pKSm4ubmxf/9+atasyapVq9i9ezdRUVHY2trKfG1CWDl5D00Uq23btjFgwADT1DI1atRg7969fPPNNwAMHz6cV1991VS/T58+2NjY0KpVK/78889CHcvW1pb+/fsDsHXrViIjI/Hx8QEgNTWVRx/Nc3YjIYSVkIQmipXWGqXUfevcvb5ixYo5ts3Nzs6OzMxM0/LNmzdNP1eqVAlbW1vTtiNHjuSdd9556NiFEGWL3HIUxapz5858/fXXXL16FYCEhATatWvHypUrAVi+fDnt27cv8P5cXFyIiooiMzOTCxcu8Msvv+R73DVr1nD58mXTcc+dO1fEsxFClGbSQhPFytXVlRkzZhAYGIitrS2enp4sXLiQUaNGMXfuXGrXrs2SJUseuJ/sVpy/vz+NGjXC3d0dNzc3vLy88qzfqlUr3nrrLbp160ZmZib29vZ89NFHNGzY0KznJ4QoPWS0fVHqRUZGMmnSJH7++WdLhyKEsLD7jbYvLTRRqkVERPD0008zZ86cAm8THR3N1q1bSUpKwtHR0fSKgBDCuklCE6Va69at+e233wpcPzo6mg0bNpCWlgZAUlISGzZsAJCkJoSVk04hwqps3brVlMyypaWlsXXrVgtFJIQoKZLQhFVJSkoqVLkQwnpIQhNWxdHRsVDlQgjrIQlNWJXOnTtjb2+fo8ze3p7OnTtbKCIhREmRTiHCqmR3/JBejkKUP5LQhNUxGAySwIQoh+SWoxBCCKsgCU0IIYRVkIQmhBDCKkhCE0IIYRUkoQkhhLAKktCEEEJYBUloQgghrIIkNCGEEFZBEpoQQgirIAlNCCGEVZCEJoQQwipIQhNCCGEVlNba0jHkSykVD5x7yM1rAVfMGI74H7m2xUOua/GRa1s8LHFdG2qta+e1olQntKJQSkVorVtbOg5rJNe2eMh1LT5ybYtHabuucstRCCGEVZCEJoQQwipYc0JbbOkArJhc2+Ih17X4yLUtHqXqulrtMzQhhBDlizW30IQQQpQjktCEEEJYBatJaEqpGkqpn5RSp+58f+Q+dW2VUoeUUt+XZIxlUUGuq1KqgVJqu1LqV6XUMaXUBEvEWlYopborpU4qpX5XSk3LY71SSi28sz5aKeVliTjLmgJc16F3rme0UmqPUsrDEnGWRQ+6tnfV81FKZSilBpRkfNmsJqEB04CtWuumwNY7y/mZAPxaIlGVfQW5runAK1rrloAf8KJSqlUJxlhmKKVsgY+Ax4FWwJA8rtXjQNM7X2OAT0o0yDKogNf1LBCotTYAb1LKOjSUVgW8ttn13gV+LNkI/8eaElpvYOmdn5cCffKqpJSqD/QA/lMyYZV5D7yuWus4rfXBOz9fJ+vDQr2SCrCM8QV+11qf0VrfBlaSdY3v1hv4QmfZBzgppZxLOtAy5oHXVWu9R2v9153FfUD9Eo6xrCrI7yzAeGAtcLkkg7ubNSW0x7TWcZD1BxZ4NJ9684FXgcwSiqusK+h1BUAp5QJ4AvuLP7QyqR5w4a7li9yb/AtSR+RU2Gv2D+C/xRqR9XjgtVVK1QP6AotKMK572Fny4IWllNoC1Mlj1YwCbt8TuKy1jlRKdTRjaGVaUa/rXftxIOsT2sta62vmiM0KqTzKcr87U5A6IqcCXzOlVBBZCa19sUZkPQpybecDU7XWGUrlVb1klKmEprXukt86pdSfSilnrXXcndszeTV7/YEnlVJPAJWA6kqpZVrrYcUUcplghuuKUsqerGS2XGv9TTGFag0uAg3uWq4PxD5EHZFTga6ZUspA1uOGx7XWV0sotrKuINe2NbDyTjKrBTyhlErXWq8vkQjvsKZbjt8BI+/8PBL4NncFrfV0rXV9rbULMBjYVt6TWQE88LqqrN/iz4Bftdbvl2BsZdEBoKlSqpFSqgJZv4ff5arzHTDiTm9HPyAp+7avyNcDr6tS6m/AN8BwrfVvFoixrHrgtdVaN9Jau9z527oGeKGkkxlYV0KbA3RVSp0Cut5ZRilVVym1yaKRlW0Fua7+wHCgk1Iq6s7XE5YJt3TTWqcD48jqCfYr8LXW+phS6nml1PN3qm0CzgC/A58CL1gk2DKkgNd1FlAT+PjO72iEhcItUwp4bUsFGfpKCCGEVbCmFpoQQohyTBKaEEIIqyAJTQghhFWQhCaEEMIqSEITQghhFSShCSGEsAqS0IQQQliF/w/YipDtoyMFfgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the embeddings\n",
    "plt.figure(figsize=(7, 7))\n",
    "for i, word in enumerate(tokenizer.word_index.keys()): \n",
    "    x, y = reduced_embeddings[i]\n",
    "    plt.scatter(x, y)\n",
    "    plt.annotate(word, xy=(x, y), xytext=(5, 2),\n",
    "                 textcoords='offset points',\n",
    "               ha='right',va='bottom')\n",
    "                \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5869e8c-a2b4-409b-a0d2-35971f63a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test_sentenses = [\n",
    "    \"we are to study\",\n",
    "    \"create programs direct processes\",\n",
    "    \"spirits process study program\",\n",
    "    \"idea study people create\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0948436-5e59-49ae-8c9b-c65d5fd1f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  ['we', 'are', 'to', 'study']\n",
      "Indexs:  [[ 4  5  6 12]]\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "Predictons:  ['we', 'are', 'to', 'study']  =>  about\n",
      "\n",
      "\n",
      "Words:  ['create', 'programs', 'direct', 'processes']\n",
      "Indexs:  [[33 34 35  3]]\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Predictons:  ['create', 'programs', 'direct', 'processes']  =>  to\n",
      "\n",
      "\n",
      "Words:  ['spirits', 'process', 'study', 'program']\n",
      "Indexs:  [[39  8 12 31]]\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Predictons:  ['spirits', 'process', 'study', 'program']  =>  the\n",
      "\n",
      "\n",
      "Words:  ['idea', 'study', 'people', 'create']\n",
      "Indexs:  [[13 12 32 33]]\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Predictons:  ['idea', 'study', 'people', 'create']  =>  programs\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for test_sentense in test_sentenses:\n",
    "    test_words = test_sentense.split(\" \")\n",
    "    print(\"Words: \", test_words)\n",
    "    \n",
    "    x_test = [] \n",
    "    for i in test_words:\n",
    "        x_test.append(word_to_index_map.get(i))\n",
    "    x_test = np.array([x_test])\n",
    "    print(\"Indexs: \", x_test)\n",
    "    \n",
    "    test_predictions = model.predict(x_test)\n",
    "    y_pred = np.argmax(test_predictions[0])\n",
    "    print(\"Predictons: \",test_words, \" => \", index_to_word_map.get(y_pred))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
